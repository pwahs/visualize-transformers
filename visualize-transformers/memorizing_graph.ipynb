{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpreting Identity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBvIU6zdIZpa"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ssx2pnTOIZpa"
      },
      "outputs": [],
      "source": [
        "TRAIN_MODEL = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7Jfz-lAWIZpb",
        "outputId": "48df1c71-5bc3-4a14-9a34-1af5c16786a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /home/pweiss/Research/.venv/lib/python3.12/site-packages (25.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_373535/1990858556.py:9: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
            "  ipython.magic(\"load_ext autoreload\")\n",
            "/tmp/ipykernel_373535/1990858556.py:10: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
            "  ipython.magic(\"autoreload 2\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipympl in /home/pweiss/Research/.venv/lib/python3.12/site-packages (0.9.6)\n",
            "Requirement already satisfied: ipython<9 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (8.31.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (8.1.5)\n",
            "Requirement already satisfied: matplotlib<4,>=3.5.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (3.10.0)\n",
            "Requirement already satisfied: numpy in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (2.2.2)\n",
            "Requirement already satisfied: pillow in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (11.1.0)\n",
            "Requirement already satisfied: traitlets<6 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (5.14.3)\n",
            "Requirement already satisfied: decorator in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (3.0.50)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (2.19.1)\n",
            "Requirement already satisfied: stack_data in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (0.6.3)\n",
            "Requirement already satisfied: comm>=0.1.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.2)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (2.9.0.post0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython<9->ipympl) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython<9->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython<9->ipympl) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from stack_data->ipython<9->ipympl) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from stack_data->ipython<9->ipympl) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from stack_data->ipython<9->ipympl) (0.2.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scipy in /home/pweiss/Research/.venv/lib/python3.12/site-packages (1.15.1)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from scipy) (2.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: manim in /home/pweiss/Research/.venv/lib/python3.12/site-packages (0.19.0)\n",
            "Requirement already satisfied: Pillow>=9.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (11.1.0)\n",
            "Requirement already satisfied: Pygments>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (2.19.1)\n",
            "Requirement already satisfied: av<14.0.0,>=9.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (13.1.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.12 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (4.12.3)\n",
            "Requirement already satisfied: click>=8.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (8.1.8)\n",
            "Requirement already satisfied: cloup>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (3.0.5)\n",
            "Requirement already satisfied: decorator>=4.3.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (5.1.1)\n",
            "Requirement already satisfied: isosurfaces>=0.1.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (0.1.2)\n",
            "Requirement already satisfied: manimpango<1.0.0,>=0.5.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (0.6.0)\n",
            "Requirement already satisfied: mapbox-earcut>=1.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (1.0.3)\n",
            "Requirement already satisfied: moderngl<6.0.0,>=5.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (5.12.0)\n",
            "Requirement already satisfied: moderngl-window>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.6 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (3.4.2)\n",
            "Requirement already satisfied: numpy>=2.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (2.2.2)\n",
            "Requirement already satisfied: pycairo<2.0.0,>=1.13 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (1.27.0)\n",
            "Requirement already satisfied: pydub>=0.20.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (0.25.1)\n",
            "Requirement already satisfied: rich>=12.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (13.9.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (1.15.1)\n",
            "Requirement already satisfied: screeninfo>=0.7 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (0.8.1)\n",
            "Requirement already satisfied: skia-pathops>=0.7.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (0.8.0.post2)\n",
            "Requirement already satisfied: srt>=3.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (3.5.3)\n",
            "Requirement already satisfied: svgelements>=1.8.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (1.9.6)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (4.12.2)\n",
            "Requirement already satisfied: watchdog>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (6.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from beautifulsoup4>=4.12->manim) (2.6)\n",
            "Requirement already satisfied: glcontext>=3.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from moderngl<6.0.0,>=5.0.0->manim) (3.0.0)\n",
            "Requirement already satisfied: pyglet>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from moderngl-window>=2.0.0->manim) (2.1.2)\n",
            "Requirement already satisfied: pyglm<3,>=2.7.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from moderngl-window>=2.0.0->manim) (2.7.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from rich>=12.0.0->manim) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->manim) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torch in /home/pweiss/Research/.venv/lib/python3.12/site-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (75.8.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "/bin/bash: Zeile 1: 2: Datei oder Verzeichnis nicht gefunden\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: einops in /home/pweiss/Research/.venv/lib/python3.12/site-packages (0.8.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: transformer_lens in /home/pweiss/Research/.venv/lib/python3.12/site-packages (2.11.0)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.14.1)\n",
            "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.0.3)\n",
            "Requirement already satisfied: datasets>=2.7.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (3.2.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.8.0)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.0.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.2.37)\n",
            "Requirement already satisfied: numpy>=1.26 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (2.2.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.10 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (2.6.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (4.48.1)\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (4.4.1)\n",
            "Requirement already satisfied: typing-extensions in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (4.12.2)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (24.2)\n",
            "Requirement already satisfied: psutil in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (6.1.1)\n",
            "Requirement already satisfied: pyyaml in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (0.28.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (0.5.2)\n",
            "Requirement already satisfied: filelock in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (19.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.11.11)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from jaxtyping>=0.2.11->transformer_lens) (0.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from rich>=12.6.0->transformer_lens) (2.19.1)\n",
            "Requirement already satisfied: networkx in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (75.8.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.10->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformers>=4.37.2->transformer_lens) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformers>=4.37.2->transformer_lens) (0.21.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (5.29.3)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (1.3.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.10->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "# Upgrade pip\n",
        "%pip install --upgrade pip\n",
        "\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "# Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "ipython.magic(\"load_ext autoreload\")\n",
        "ipython.magic(\"autoreload 2\")\n",
        "ipython.run_line_magic(\"pip\", \"install ipympl\")\n",
        "ipython.run_line_magic(\"pip\", \"install scipy\")\n",
        "ipython.run_line_magic(\"pip\", \"install manim\")\n",
        "ipython.run_line_magic(\"pip\", \"install torch\")\n",
        "ipython.run_line_magic(\"pip\", \"install numpy<2\")\n",
        "ipython.run_line_magic(\"pip\", \"install einops\")\n",
        "ipython.run_line_magic(\"pip\", \"install transformer_lens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i8GCNEdpIZpc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import tqdm.auto as tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "import copy\n",
        "\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, ActivationCache\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "# Define the location to save the model, using a relative path\n",
        "PTH_LOCATION = \"workspace/_scratch/identity.pth\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(Path(PTH_LOCATION).parent, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M2Nzu7EIZpe"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOckI2-GIZpe"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_2OXlPG-IZpe"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = 3\n",
        "OUTPUT_DIM = 3\n",
        "frac_train = 1\n",
        "\n",
        "# Optimizer config\n",
        "lr = 1e-3\n",
        "wd = 1e-2\n",
        "betas = (0.9, 0.999)\n",
        "\n",
        "num_epochs = 10000\n",
        "checkpoint_every = 500\n",
        "\n",
        "DATA_SEED = 599"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT7xY9WsIZpe"
      },
      "source": [
        "## Define Task\n",
        "* Define random function\n",
        "* Define the dataset & labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOJMbA26IZpe"
      },
      "source": [
        "Input format:\n",
        "|a|b|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I8Af2zLZIZpf",
        "outputId": "5075c607-e865-4b8c-90df-d2685d17ebb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 1],\n",
            "        [0, 2],\n",
            "        [1, 0],\n",
            "        [1, 1],\n",
            "        [1, 2],\n",
            "        [2, 0],\n",
            "        [2, 1],\n",
            "        [2, 2]], device='cuda:0')\n",
            "tensor([2, 2, 1, 0, 2, 2, 0, 0, 2], device='cuda:0')\n",
            "torch.Size([9, 2])\n",
            "tensor([], device='cuda:0', size=(0, 2), dtype=torch.int64)\n",
            "tensor([], device='cuda:0', dtype=torch.int64)\n",
            "torch.Size([0, 2])\n"
          ]
        }
      ],
      "source": [
        "def get_training_data(input_dim = INPUT_DIM, output_dim = OUTPUT_DIM, data_seed = DATA_SEED):\n",
        "    torch.manual_seed(data_seed)\n",
        "    a_vector = torch.arange(input_dim)\n",
        "    dataset = torch.cartesian_prod(a_vector, a_vector).to(device)\n",
        "\n",
        "    labels = torch.randint(0, output_dim, (dataset.shape[0],), device=device)\n",
        "    train_data = dataset\n",
        "    train_labels = labels\n",
        "    # For now no test data\n",
        "    test_data = dataset[0:0]\n",
        "    test_labels = labels[0:0]\n",
        "    print(train_data)\n",
        "    print(train_labels)\n",
        "    print(train_data.shape)\n",
        "    print(test_data[:5])\n",
        "    print(test_labels[:5])\n",
        "    print(test_data.shape)\n",
        "    return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = get_training_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_83i1bUkIZpf"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UL7gVZ9WIZpf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_seeded_model(seed = 999, input_dim = INPUT_DIM, output_dim = OUTPUT_DIM):\n",
        "    cfg = HookedTransformerConfig(\n",
        "        n_layers = 1,\n",
        "        n_heads = 1,\n",
        "        d_model = 2,\n",
        "        d_head = 2,\n",
        "        d_mlp = None,\n",
        "        attn_only=True,\n",
        "        act_fn = \"relu\",\n",
        "        normalization_type=None,\n",
        "        d_vocab=input_dim,\n",
        "        d_vocab_out=output_dim,\n",
        "        n_ctx=2,\n",
        "        init_weights=True,\n",
        "        device=device,\n",
        "        seed = seed,\n",
        "    )\n",
        "    model = HookedTransformer(cfg)\n",
        "    # Biases are enabled by default\n",
        "    # for name, param in model.named_parameters():\n",
        "    #     if \"b_\" in name:\n",
        "    #         param.requires_grad = False\n",
        "    return model\n",
        "\n",
        "model = get_seeded_model(seed = 993)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lctx1jAtIZpg"
      },
      "source": [
        "## Define Optimizer + Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 1],\n",
            "        [0, 2],\n",
            "        [1, 0],\n",
            "        [1, 1],\n",
            "        [1, 2],\n",
            "        [2, 0],\n",
            "        [2, 1],\n",
            "        [2, 2]], device='cuda:0')\n",
            "tensor([[[-0.0232, -0.3831,  0.0734],\n",
            "         [ 0.3973,  0.0077,  0.2572]],\n",
            "\n",
            "        [[-0.0232, -0.3831,  0.0734],\n",
            "         [ 0.1674, -0.1676,  0.1479]],\n",
            "\n",
            "        [[-0.0232, -0.3831,  0.0734],\n",
            "         [ 0.1926,  0.8592, -0.0728]],\n",
            "\n",
            "        [[-0.3110, -0.5506, -0.0756],\n",
            "         [ 0.3419,  0.0151,  0.2194]],\n",
            "\n",
            "        [[-0.3110, -0.5506, -0.0756],\n",
            "         [ 0.1117, -0.1603,  0.1098]],\n",
            "\n",
            "        [[-0.3110, -0.5506, -0.0756],\n",
            "         [ 0.1047,  0.8789, -0.1347]],\n",
            "\n",
            "        [[-0.0824,  0.2363, -0.1083],\n",
            "         [ 0.4788, -0.1707,  0.3516]],\n",
            "\n",
            "        [[-0.0824,  0.2363, -0.1083],\n",
            "         [ 0.2537, -0.3527,  0.2469]],\n",
            "\n",
            "        [[-0.0824,  0.2363, -0.1083],\n",
            "         [ 0.3217,  0.6311,  0.0640]]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(train_data)\n",
        "print(model(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dJORAU_PIZpg",
        "outputId": "1c2b9f25-056e-4e0d-defc-0bd11586136d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0589, device='cuda:0', dtype=torch.float64, grad_fn=<NegBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<NegBackward0>)\n",
            "Uniform loss:\n",
            "2.1972245773362196\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=betas)\n",
        "def loss_fn(logits, labels):\n",
        "    if len(logits.shape)==3:\n",
        "        logits = logits[:, -1]\n",
        "    logits = logits.to(torch.float64)\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    correct_log_probs = log_probs.gather(dim=-1, index=labels[:, None])[:, 0]\n",
        "    return -correct_log_probs.mean()\n",
        "train_logits = model(train_data)\n",
        "train_loss = loss_fn(train_logits, train_labels)\n",
        "print(train_loss)\n",
        "test_logits = model(test_data)\n",
        "test_loss = loss_fn(test_logits, test_labels)\n",
        "print(test_loss)\n",
        "print(\"Uniform loss:\")\n",
        "print(np.log(INPUT_DIM * INPUT_DIM))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW9Q4bIcIZpg"
      },
      "source": [
        "## Actually Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj4h2LIRIZpg"
      },
      "source": [
        "**Weird Decision:** Training the model with full batch training rather than stochastic gradient descent. We do this so to make training smoother and reduce the number of slingshots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_stats(model):\n",
        "    # Extract the p 2-dimensional tensors, vector i is vec[:, i]\n",
        "    vec = model.W_U.data\n",
        "\n",
        "    # Function to compute the angle between two vectors\n",
        "    def compute_angle(v1, v2):\n",
        "        cos_theta = torch.dot(v1, v2) / (torch.norm(v1) * torch.norm(v2))\n",
        "        angle = torch.acos(cos_theta) * (180.0 / np.pi)\n",
        "        return angle\n",
        "\n",
        "    # Compute pairwise angles\n",
        "    # for i in range(vec.shape[1]):\n",
        "    #     for j in range(i+1, vec.shape[1]):\n",
        "    #         angle = compute_angle(vec[:, i], vec[:, j])\n",
        "    #         print(f\"Angle between {i} and {j}: {angle.item():.2f}°\")\n",
        "    #     print(f\"Norm of vector {i}: {torch.norm(vec[:, i]):.2f}\")\n",
        "\n",
        "print_stats(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c477d3a6463646deb7cf1de99bb0199a"
          ]
        },
        "id": "UsZLeCMeIZph",
        "outputId": "133f3502-ca28-490c-c030-f60b751dcd7b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28d0e176859c4c6485c7c1e1111e0d4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 499 Train Loss 0.29249830089483286 Test Loss nan\n",
            "Epoch 999 Train Loss 0.007191911337200549 Test Loss nan\n",
            "Epoch 1499 Train Loss 0.0014405720831221199 Test Loss nan\n",
            "Epoch 1999 Train Loss 0.00058029673601262 Test Loss nan\n",
            "Epoch 2499 Train Loss 0.0003284101123300776 Test Loss nan\n",
            "Epoch 2999 Train Loss 0.00021724479503701545 Test Loss nan\n",
            "Epoch 3499 Train Loss 0.00015535814172684345 Test Loss nan\n",
            "Epoch 3999 Train Loss 0.00011568451699566024 Test Loss nan\n",
            "Epoch 4499 Train Loss 8.792135399450594e-05 Test Loss nan\n",
            "Epoch 4999 Train Loss 6.747485205537347e-05 Test Loss nan\n",
            "Epoch 5499 Train Loss 5.198427730211382e-05 Test Loss nan\n",
            "Epoch 5999 Train Loss 4.007538298144928e-05 Test Loss nan\n",
            "Epoch 6499 Train Loss 3.086240462973342e-05 Test Loss nan\n",
            "Epoch 6999 Train Loss 2.372493628699817e-05 Test Loss nan\n",
            "Epoch 7499 Train Loss 1.8209154946826858e-05 Test Loss nan\n",
            "Epoch 7999 Train Loss 1.3953107354059887e-05 Test Loss nan\n",
            "Epoch 8499 Train Loss 1.0676792754563315e-05 Test Loss nan\n",
            "Epoch 8999 Train Loss 8.161631034735696e-06 Test Loss nan\n",
            "Epoch 9499 Train Loss 6.235055275629679e-06 Test Loss nan\n",
            "Epoch 9999 Train Loss 4.761511982034684e-06 Test Loss nan\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, train_data, train_labels, test_data, test_labels, num_epochs = num_epochs, loss_target = None):\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(), lr=lr, weight_decay=wd, betas=betas\n",
        "    )\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    model_checkpoints = []\n",
        "    checkpoint_epochs = []\n",
        "    if TRAIN_MODEL:\n",
        "        for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "            train_logits = model(train_data)\n",
        "            train_loss = loss_fn(train_logits, train_labels)\n",
        "            train_loss.backward()\n",
        "            train_losses.append(train_loss.item())\n",
        "            if loss_target is not None and train_loss.item() < loss_target:\n",
        "                print(f\"Loss target {loss_target} reached with loss {train_loss.item()} at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.inference_mode():\n",
        "                test_logits = model(test_data)\n",
        "                test_loss = loss_fn(test_logits, test_labels)\n",
        "                test_losses.append(test_loss.item())\n",
        "\n",
        "            if ((epoch+1)%checkpoint_every)==0:\n",
        "                checkpoint_epochs.append(epoch)\n",
        "                model_checkpoints.append(copy.deepcopy(model.state_dict()))\n",
        "                print_stats(model)\n",
        "                print(f\"Epoch {epoch} Train Loss {train_loss.item()} Test Loss {test_loss.item()}\")\n",
        "    if TRAIN_MODEL:\n",
        "        torch.save(\n",
        "            {\n",
        "                \"model\":model.state_dict(),\n",
        "                \"config\": model.cfg,\n",
        "                \"checkpoints\": model_checkpoints,\n",
        "                \"checkpoint_epochs\": checkpoint_epochs,\n",
        "                \"test_losses\": test_losses,\n",
        "                \"train_losses\": train_losses,\n",
        "            },\n",
        "            PTH_LOCATION)\n",
        "\n",
        "train_model(\n",
        "    model, train_data, train_labels, test_data, test_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EzRKi7J7IZph"
      },
      "outputs": [],
      "source": [
        "if not TRAIN_MODEL:\n",
        "    cached_data = torch.load(PTH_LOCATION)\n",
        "    model.load_state_dict(cached_data['model'])\n",
        "    model_checkpoints = cached_data[\"checkpoints\"]\n",
        "    checkpoint_epochs = cached_data[\"checkpoint_epochs\"]\n",
        "    test_losses = cached_data['test_losses']\n",
        "    train_losses = cached_data['train_losses']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transposed Input:\n",
            " tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
            "        [0, 1, 2, 0, 1, 2, 0, 1, 2]], device='cuda:0')\n",
            "Labels:  tensor([2, 2, 1, 0, 2, 2, 0, 0, 2], device='cuda:0')\n",
            "Logits of last token:\n",
            " tensor([[ -6.4230,  -1.9307,  10.7630],\n",
            "        [ -4.4916,  -8.5375,  12.1585],\n",
            "        [ -1.7896,   9.3899,  -3.5204],\n",
            "        [  6.9543,  -4.1992,  -7.7939],\n",
            "        [ -4.3770,  -8.4497,  11.9299],\n",
            "        [ -1.8799, -12.0370,  10.5191],\n",
            "        [ 10.5641, -12.7535,  -7.6477],\n",
            "        [  7.4779,  -9.8636,  -4.9022],\n",
            "        [ -2.8386, -14.7257,  13.6992]], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Unembed:\n",
            " tensor([[-1.0812,  2.0407,  0.2946],\n",
            "        [ 0.7589,  0.2098, -1.2724]], device='cuda:0')\n",
            "Last layer before unembed:\n",
            " tensor([[ -0.0272,  -8.3789],\n",
            "        [ -3.0794, -10.1822],\n",
            "        [  4.2643,   3.8404],\n",
            "        [ -2.5773,   5.6153],\n",
            "        [ -3.0554,  -9.9970],\n",
            "        [ -4.8838,  -9.3115],\n",
            "        [ -6.6602,   4.5551],\n",
            "        [ -5.0603,   2.7677],\n",
            "        [ -5.9198, -12.0507]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def create_cache(model):\n",
        "    input = train_data\n",
        "    print(\"Transposed Input:\\n\", input.transpose(0, 1))\n",
        "    logits, cache = model.run_with_cache(input)\n",
        "    print(\"Labels: \", train_labels)\n",
        "    print(\"Logits of last token:\\n\", logits[:, -1, :])\n",
        "    print(\"Unembed:\\n\", model.W_U.data)\n",
        "    print(\"Last layer before unembed:\\n\", cache.cache_dict[\"blocks.0.hook_resid_post\"][:, -1, :])\n",
        "    return cache\n",
        "\n",
        "cache = create_cache(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'hook_embed': tensor([[[-1.1449,  0.6601],\n",
              "          [-1.1449,  0.6601]],\n",
              " \n",
              "         [[-1.1449,  0.6601],\n",
              "          [ 0.3006, -0.1175]],\n",
              " \n",
              "         [[-1.1449,  0.6601],\n",
              "          [ 1.5386, -0.9611]],\n",
              " \n",
              "         [[ 0.3006, -0.1175],\n",
              "          [-1.1449,  0.6601]],\n",
              " \n",
              "         [[ 0.3006, -0.1175],\n",
              "          [ 0.3006, -0.1175]],\n",
              " \n",
              "         [[ 0.3006, -0.1175],\n",
              "          [ 1.5386, -0.9611]],\n",
              " \n",
              "         [[ 1.5386, -0.9611],\n",
              "          [-1.1449,  0.6601]],\n",
              " \n",
              "         [[ 1.5386, -0.9611],\n",
              "          [ 0.3006, -0.1175]],\n",
              " \n",
              "         [[ 1.5386, -0.9611],\n",
              "          [ 1.5386, -0.9611]]], device='cuda:0'),\n",
              " 'hook_pos_embed': tensor([[[ 0.5616,  0.9027],\n",
              "          [-0.6252, -1.5300]],\n",
              " \n",
              "         [[ 0.5616,  0.9027],\n",
              "          [-0.6252, -1.5300]],\n",
              " \n",
              "         [[ 0.5616,  0.9027],\n",
              "          [-0.6252, -1.5300]],\n",
              " \n",
              "         [[ 0.5616,  0.9027],\n",
              "          [-0.6252, -1.5300]],\n",
              " \n",
              "         [[ 0.5616,  0.9027],\n",
              "          [-0.6252, -1.5300]],\n",
              " \n",
              "         [[ 0.5616,  0.9027],\n",
              "          [-0.6252, -1.5300]],\n",
              " \n",
              "         [[ 0.5616,  0.9027],\n",
              "          [-0.6252, -1.5300]],\n",
              " \n",
              "         [[ 0.5616,  0.9027],\n",
              "          [-0.6252, -1.5300]],\n",
              " \n",
              "         [[ 0.5616,  0.9027],\n",
              "          [-0.6252, -1.5300]]], device='cuda:0'),\n",
              " 'blocks.0.hook_resid_pre': tensor([[[-0.5833,  1.5629],\n",
              "          [-1.7701, -0.8698]],\n",
              " \n",
              "         [[-0.5833,  1.5629],\n",
              "          [-0.3246, -1.6475]],\n",
              " \n",
              "         [[-0.5833,  1.5629],\n",
              "          [ 0.9134, -2.4911]],\n",
              " \n",
              "         [[ 0.8621,  0.7852],\n",
              "          [-1.7701, -0.8698]],\n",
              " \n",
              "         [[ 0.8621,  0.7852],\n",
              "          [-0.3246, -1.6475]],\n",
              " \n",
              "         [[ 0.8621,  0.7852],\n",
              "          [ 0.9134, -2.4911]],\n",
              " \n",
              "         [[ 2.1002, -0.0584],\n",
              "          [-1.7701, -0.8698]],\n",
              " \n",
              "         [[ 2.1002, -0.0584],\n",
              "          [-0.3246, -1.6475]],\n",
              " \n",
              "         [[ 2.1002, -0.0584],\n",
              "          [ 0.9134, -2.4911]]], device='cuda:0'),\n",
              " 'blocks.0.attn.hook_q': tensor([[[[-2.3254,  0.4960]],\n",
              " \n",
              "          [[-3.5381,  4.8472]]],\n",
              " \n",
              " \n",
              "         [[[-2.3254,  0.4960]],\n",
              " \n",
              "          [[-0.0740,  3.0141]]],\n",
              " \n",
              " \n",
              "         [[[-2.3254,  0.4960]],\n",
              " \n",
              "          [[ 2.9873,  1.6085]]],\n",
              " \n",
              " \n",
              "         [[[ 1.1386, -1.3372]],\n",
              " \n",
              "          [[-3.5381,  4.8472]]],\n",
              " \n",
              " \n",
              "         [[[ 1.1386, -1.3372]],\n",
              " \n",
              "          [[-0.0740,  3.0141]]],\n",
              " \n",
              " \n",
              "         [[[ 1.1386, -1.3372]],\n",
              " \n",
              "          [[ 2.9873,  1.6085]]],\n",
              " \n",
              " \n",
              "         [[[ 4.1999, -2.7428]],\n",
              " \n",
              "          [[-3.5381,  4.8472]]],\n",
              " \n",
              " \n",
              "         [[[ 4.1999, -2.7428]],\n",
              " \n",
              "          [[-0.0740,  3.0141]]],\n",
              " \n",
              " \n",
              "         [[[ 4.1999, -2.7428]],\n",
              " \n",
              "          [[ 2.9873,  1.6085]]]], device='cuda:0'),\n",
              " 'blocks.0.attn.hook_k': tensor([[[[ 2.4994, -3.3348]],\n",
              " \n",
              "          [[ 4.2316, -1.2359]]],\n",
              " \n",
              " \n",
              "         [[[ 2.4994, -3.3348]],\n",
              " \n",
              "          [[-0.1066,  2.1252]]],\n",
              " \n",
              " \n",
              "         [[[ 2.4994, -3.3348]],\n",
              " \n",
              "          [[-3.9280,  5.2848]]],\n",
              " \n",
              " \n",
              "         [[[-1.8388,  0.0263]],\n",
              " \n",
              "          [[ 4.2316, -1.2359]]],\n",
              " \n",
              " \n",
              "         [[[-1.8388,  0.0263]],\n",
              " \n",
              "          [[-0.1066,  2.1252]]],\n",
              " \n",
              " \n",
              "         [[[-1.8388,  0.0263]],\n",
              " \n",
              "          [[-3.9280,  5.2848]]],\n",
              " \n",
              " \n",
              "         [[[-5.6602,  3.1860]],\n",
              " \n",
              "          [[ 4.2316, -1.2359]]],\n",
              " \n",
              " \n",
              "         [[[-5.6602,  3.1860]],\n",
              " \n",
              "          [[-0.1066,  2.1252]]],\n",
              " \n",
              " \n",
              "         [[[-5.6602,  3.1860]],\n",
              " \n",
              "          [[-3.9280,  5.2848]]]], device='cuda:0'),\n",
              " 'blocks.0.attn.hook_v': tensor([[[[-3.5159,  0.5056]],\n",
              " \n",
              "          [[ 2.2176,  2.6192]]],\n",
              " \n",
              " \n",
              "         [[[-3.5159,  0.5056]],\n",
              " \n",
              "          [[ 3.8176,  0.4706]]],\n",
              " \n",
              " \n",
              "         [[[-3.5159,  0.5056]],\n",
              " \n",
              "          [[ 5.5954, -1.3495]]],\n",
              " \n",
              " \n",
              "         [[[-1.9158, -1.6430]],\n",
              " \n",
              "          [[ 2.2176,  2.6192]]],\n",
              " \n",
              " \n",
              "         [[[-1.9158, -1.6430]],\n",
              " \n",
              "          [[ 3.8176,  0.4706]]],\n",
              " \n",
              " \n",
              "         [[[-1.9158, -1.6430]],\n",
              " \n",
              "          [[ 5.5954, -1.3495]]],\n",
              " \n",
              " \n",
              "         [[[-0.1380, -3.4631]],\n",
              " \n",
              "          [[ 2.2176,  2.6192]]],\n",
              " \n",
              " \n",
              "         [[[-0.1380, -3.4631]],\n",
              " \n",
              "          [[ 3.8176,  0.4706]]],\n",
              " \n",
              " \n",
              "         [[[-0.1380, -3.4631]],\n",
              " \n",
              "          [[ 5.5954, -1.3495]]]], device='cuda:0'),\n",
              " 'blocks.0.attn.hook_attn_scores': tensor([[[[ -5.2794,     -inf],\n",
              "           [-17.6830, -14.8228]]],\n",
              " \n",
              " \n",
              "         [[[ -5.2794,     -inf],\n",
              "           [ -7.2381,   4.5349]]],\n",
              " \n",
              " \n",
              "         [[[ -5.2794,     -inf],\n",
              "           [  1.4868,  -2.2864]]],\n",
              " \n",
              " \n",
              "         [[[ -1.5053,     -inf],\n",
              "           [  4.6905, -14.8228]]],\n",
              " \n",
              " \n",
              "         [[[ -1.5053,     -inf],\n",
              "           [  0.1524,   4.5349]]],\n",
              " \n",
              " \n",
              "         [[[ -1.5053,     -inf],\n",
              "           [ -3.8541,  -2.2864]]],\n",
              " \n",
              " \n",
              "         [[[-22.9886,     -inf],\n",
              "           [ 25.0805, -14.8228]]],\n",
              " \n",
              " \n",
              "         [[[-22.9886,     -inf],\n",
              "           [  7.0864,   4.5349]]],\n",
              " \n",
              " \n",
              "         [[[-22.9886,     -inf],\n",
              "           [ -8.3325,  -2.2864]]]], device='cuda:0'),\n",
              " 'blocks.0.attn.hook_pattern': tensor([[[[1.0000e+00, 0.0000e+00],\n",
              "           [5.4154e-02, 9.4585e-01]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [7.7099e-06, 9.9999e-01]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [9.7754e-01, 2.2462e-02]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [1.0000e+00, 3.3536e-09]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [1.2339e-02, 9.8766e-01]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [1.7255e-01, 8.2745e-01]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [1.0000e+00, 4.6797e-18]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [9.2767e-01, 7.2330e-02]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [2.3615e-03, 9.9764e-01]]]], device='cuda:0'),\n",
              " 'blocks.0.attn.hook_z': tensor([[[[-3.5159,  0.5056]],\n",
              " \n",
              "          [[ 1.9071,  2.5048]]],\n",
              " \n",
              " \n",
              "         [[[-3.5159,  0.5056]],\n",
              " \n",
              "          [[ 3.8176,  0.4706]]],\n",
              " \n",
              " \n",
              "         [[[-3.5159,  0.5056]],\n",
              " \n",
              "          [[-3.3112,  0.4639]]],\n",
              " \n",
              " \n",
              "         [[[-1.9158, -1.6430]],\n",
              " \n",
              "          [[-1.9158, -1.6430]]],\n",
              " \n",
              " \n",
              "         [[[-1.9158, -1.6430]],\n",
              " \n",
              "          [[ 3.7469,  0.4445]]],\n",
              " \n",
              " \n",
              "         [[[-1.9158, -1.6430]],\n",
              " \n",
              "          [[ 4.2993, -1.4002]]],\n",
              " \n",
              " \n",
              "         [[[-0.1380, -3.4631]],\n",
              " \n",
              "          [[-0.1380, -3.4631]]],\n",
              " \n",
              " \n",
              "         [[[-0.1380, -3.4631]],\n",
              " \n",
              "          [[ 0.1481, -3.1786]]],\n",
              " \n",
              " \n",
              "         [[[-0.1380, -3.4631]],\n",
              " \n",
              "          [[ 5.5819, -1.3545]]]], device='cuda:0'),\n",
              " 'blocks.0.hook_attn_out': tensor([[[ 3.5850,  6.6975],\n",
              "          [ 1.7428, -7.5090]],\n",
              " \n",
              "         [[ 3.5850,  6.6975],\n",
              "          [-2.7548, -8.5347]],\n",
              " \n",
              "         [[ 3.5850,  6.6975],\n",
              "          [ 3.3509,  6.3315]],\n",
              " \n",
              "         [[-0.8072,  6.4851],\n",
              "          [-0.8072,  6.4851]],\n",
              " \n",
              "         [[-0.8072,  6.4851],\n",
              "          [-2.7308, -8.3495]],\n",
              " \n",
              "         [[-0.8072,  6.4851],\n",
              "          [-5.7972, -6.8204]],\n",
              " \n",
              "         [[-4.8902,  5.4249],\n",
              "          [-4.8902,  5.4249]],\n",
              " \n",
              "         [[-4.8902,  5.4249],\n",
              "          [-4.7357,  4.4152]],\n",
              " \n",
              "         [[-4.8902,  5.4249],\n",
              "          [-6.8332, -9.5596]]], device='cuda:0'),\n",
              " 'blocks.0.hook_resid_post': tensor([[[  3.0017,   8.2604],\n",
              "          [ -0.0272,  -8.3789]],\n",
              " \n",
              "         [[  3.0017,   8.2604],\n",
              "          [ -3.0794, -10.1822]],\n",
              " \n",
              "         [[  3.0017,   8.2604],\n",
              "          [  4.2643,   3.8404]],\n",
              " \n",
              "         [[  0.0549,   7.2703],\n",
              "          [ -2.5773,   5.6153]],\n",
              " \n",
              "         [[  0.0549,   7.2703],\n",
              "          [ -3.0554,  -9.9970]],\n",
              " \n",
              "         [[  0.0549,   7.2703],\n",
              "          [ -4.8838,  -9.3115]],\n",
              " \n",
              "         [[ -2.7900,   5.3665],\n",
              "          [ -6.6602,   4.5551]],\n",
              " \n",
              "         [[ -2.7900,   5.3665],\n",
              "          [ -5.0603,   2.7677]],\n",
              " \n",
              "         [[ -2.7900,   5.3665],\n",
              "          [ -5.9198, -12.0507]]], device='cuda:0')}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get a list of all activations stored in the cache, especially their names\n",
        "cache.cache_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Animations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pweiss/Research/.venv/lib/python3.12/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
            "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
          ]
        }
      ],
      "source": [
        "from manim import *\n",
        "\n",
        "config.media_width = \"80%\"\n",
        "config.verbosity = \"WARNING\"\n",
        "config.preview = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[tensor([-1.1449,  0.6601])(#FFFFFF)], [tensor([-0.5833,  1.5629])(#FFFFFF)], [tensor([3.0017, 8.2604])(#888888)]]\n"
          ]
        }
      ],
      "source": [
        "class VectorParams:\n",
        "    def __init__(self, values = [], color = WHITE, label = \"\"):\n",
        "        self.values = values\n",
        "        self.color = color\n",
        "        self.label = label\n",
        "    def __repr__(self) -> str:\n",
        "        return str(self.values) + \"(\" + str(self.color) + \")\"\n",
        "\n",
        "class Data:\n",
        "    def __init__(self):\n",
        "        self.vectors: list[list[VectorParams]] = [[]]\n",
        "        self.steps = 0\n",
        "        self.current_labels = set()\n",
        "\n",
        "    def add_vector(self, vector, color = WHITE, label = \"\"):\n",
        "        if label not in self.current_labels:\n",
        "            self.current_labels.add(label)\n",
        "            self.vectors[self.steps].append(VectorParams(values = vector, color = color, label = label))\n",
        "\n",
        "    def next_step(self):\n",
        "        self.steps += 1\n",
        "        self.vectors.append([])\n",
        "        self.current_labels = set()\n",
        "\n",
        "    def add_vectors_at_hook(self, c: ActivationCache, hook: str, color0 = WHITE, color1 = WHITE, input_labels = None, input_colors = None):\n",
        "        if input_labels is None:\n",
        "            input_labels = [\"\" for i in range(c.cache_dict[hook].shape[0])]\n",
        "        for i in range(c.cache_dict[hook].shape[0]):\n",
        "            self.add_vector(c.cache_dict[hook][i][0].cpu(), color = color0, label = input_labels[i][:1])\n",
        "            self.add_vector(\n",
        "                c.cache_dict[hook][i][1].cpu(), color=color1 if input_colors is None else input_colors[i], label=input_labels[i][:2]\n",
        "            )\n",
        "\n",
        "\n",
        "def compile_data_vectors(cache, input_labels=None, input_colors=None):\n",
        "    # Set default value as list of empty strings\n",
        "    vectors = Data()\n",
        "    vectors.add_vectors_at_hook(cache, \"hook_embed\", color1 = GRAY, input_labels=input_labels, input_colors=input_colors)\n",
        "    vectors.next_step()\n",
        "    vectors.add_vectors_at_hook(cache, \"blocks.0.hook_resid_pre\", input_labels=input_labels, input_colors=input_colors)\n",
        "    vectors.next_step()\n",
        "    vectors.add_vectors_at_hook(cache, \"blocks.0.hook_resid_post\", color0 = GRAY, input_labels=input_labels, input_colors=input_colors)\n",
        "    # vectors.add_vectors_at_hook(cache, \"blocks.0.hook_resid_mid\")\n",
        "\n",
        "    print(vectors.vectors)\n",
        "    return vectors\n",
        "\n",
        "\n",
        "vectors = compile_data_vectors(cache)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def change_font_size(labeled_arrow: LabeledArrow, new_size):\n",
        "    # print(labeled_arrow, labeled_arrow.submobjects)\n",
        "    # print(labeled_arrow.submobjects[-1].font_size)\n",
        "    if not isinstance(labeled_arrow, LabeledArrow):\n",
        "        return\n",
        "    label = labeled_arrow.submobjects[-1]\n",
        "    box = labeled_arrow.submobjects[-2]\n",
        "    if not isinstance(box, BackgroundRectangle):\n",
        "        box = labeled_arrow.submobjects[-3]\n",
        "    coords = label.get_center()\n",
        "    # print(new_size)\n",
        "    labeled_arrow.submobjects[-1] = MathTex(\n",
        "        label.get_tex_string(), color=label.color, font_size=new_size\n",
        "    )\n",
        "    # print(\"size=\", labeled_arrow.submobjects[-1].font_size)\n",
        "    label = labeled_arrow.submobjects[-1]\n",
        "    label.move_to(coords)\n",
        "    box.width = label.width + 2 * box.buff\n",
        "    box.height = label.height + 2 * box.buff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "DOT_SCALE = 0.05\n",
        "class VisualizeTransformer(MovingCameraScene):\n",
        "    def construct(self):\n",
        "        print(\"v=\", vectors.vectors)\n",
        "        axes = Axes(\n",
        "            x_range = [-20, 20, 1],\n",
        "            y_range = [-20, 20, 1],\n",
        "            x_axis_config={\n",
        "                \"numbers_to_include\": np.arange(-18, 18.1, 3),\n",
        "                \"font_size\": 24\n",
        "            },\n",
        "            y_axis_config={\n",
        "                \"numbers_to_include\": np.arange(-18, 18.1, 3), \n",
        "                \"font_size\": 24            \n",
        "            },\n",
        "            x_length = 40,\n",
        "            y_length = 40,\n",
        "            axis_config={\"color\": GREEN}\n",
        "        )\n",
        "\n",
        "        scale = ValueTracker(2)\n",
        "\n",
        "        dots = VGroup()\n",
        "        def update_scale(self):\n",
        "            return\n",
        "            # TODO: Make the scaling nicer\n",
        "            self.stroke_width = 6 * scale.get_value()\n",
        "            change_font_size(self, 48 * scale.get_value())\n",
        "            # print(\"New font size: \", self.font_size)\n",
        "\n",
        "        # Embedding arrows\n",
        "        for i, t in enumerate(vectors.vectors[0]):\n",
        "            # print(t, t.numpy())\n",
        "            # arrow = LabeledArrow(\n",
        "            #     start=ORIGIN,\n",
        "            #     end=np.append(t.values.numpy(), 0),\n",
        "            #     buff = 0,\n",
        "            #     label = t.label,\n",
        "            #     label_frame = False,\n",
        "            #     label_color=YELLOW,\n",
        "            #     color = t.color,\n",
        "            #     max_stroke_width_to_length_ratio = 100,\n",
        "            # )\n",
        "\n",
        "            # arrow.add_updater(update_scale)\n",
        "            # arrows.add(arrow)\n",
        "            dot = LabeledDot(\n",
        "                point=np.append(t.values.numpy(), 0),\n",
        "                label=t.label,\n",
        "                color=t.color,\n",
        "                radius=DOT_SCALE * (len(vectors.vectors[0]) - i) + 0.2,\n",
        "            )\n",
        "\n",
        "            dot.set_opacity(0.5)\n",
        "\n",
        "            dot.add_updater(update_scale)\n",
        "            dots.add(dot)\n",
        "\n",
        "        # Transitioning the arrows through the model\n",
        "        self.add(axes, axes.get_axis_labels(), dots)\n",
        "        for step in range(1, len(vectors.vectors)):\n",
        "            new_dots = VGroup()\n",
        "            transition_arrows = VGroup()\n",
        "            for i, t in enumerate(vectors.vectors[step]):\n",
        "                # print(t, t.numpy())\n",
        "                # new_arrow = LabeledArrow(\n",
        "                #     start=ORIGIN,\n",
        "                #     end=np.append(t.values.numpy(), 0),\n",
        "                #     buff=0,\n",
        "                #     label=t.label,\n",
        "                #     label_frame=False,\n",
        "                #     label_color=YELLOW,\n",
        "                #     color=t.color,\n",
        "                #     max_stroke_width_to_length_ratio=100,\n",
        "                # )\n",
        "                # new_arrow.add_updater(update_scale)\n",
        "                # new_arrows.add(new_arrow)\n",
        "                new_dot = LabeledDot(\n",
        "                    point=np.append(t.values.numpy(), 0),\n",
        "                    label=t.label,\n",
        "                    color=t.color,\n",
        "                    radius = DOT_SCALE * (len(vectors.vectors[step]) - i) + 0.2,\n",
        "                )\n",
        "                new_dot.set_opacity(0.5)\n",
        "                new_dot.add_updater(update_scale)\n",
        "                new_dots.add(new_dot)\n",
        "\n",
        "                transition_arrow = Arrow(\n",
        "                    start=dots[i].arc_center,\n",
        "                    end=new_dots[i].arc_center,\n",
        "                    buff=0,\n",
        "                    color=RED,\n",
        "                )\n",
        "                transition_arrow.add_updater(update_scale)\n",
        "                transition_arrows.add(transition_arrow)\n",
        "\n",
        "            view = SurroundingRectangle(new_dots)\n",
        "            factor = max(\n",
        "                view.width / self.camera.frame_width,\n",
        "                view.height / self.camera.frame_height,\n",
        "            )\n",
        "            print(\n",
        "                factor,\n",
        "                self.camera.frame_width, view.width,\n",
        "                self.camera.frame_height, view.height,\n",
        "            )\n",
        "            self.wait()\n",
        "            self.play(FadeIn(transition_arrows), self.camera.auto_zoom(view, margin = 2), scale.animate.set_value(scale.get_value() * factor))\n",
        "            self.wait()\n",
        "            self.play(\n",
        "                ReplacementTransform(dots, new_dots)\n",
        "            )\n",
        "            self.wait()\n",
        "            self.play(FadeOut(transition_arrows))\n",
        "            self.wait()\n",
        "            dots = new_dots\n",
        "\n",
        "        # Unembedding Arrows\n",
        "        embedding_arrows = VGroup()\n",
        "        data = model.W_U.data\n",
        "        print(\"unembed: \", data)\n",
        "        for i in range(data.size()[1]):\n",
        "            embedding_arrow = LabeledArrow(\n",
        "                start=ORIGIN,\n",
        "                end=[data[0, i].item(), data[1, i].item(), 0],\n",
        "                label=str(i),\n",
        "                color=LIGHT_PINK,\n",
        "                buff=0,\n",
        "                max_stroke_width_to_length_ratio=100,\n",
        "            )\n",
        "            embedding_arrows.add(embedding_arrow)\n",
        "        self.play(FadeIn(embedding_arrows))\n",
        "        self.wait()\n",
        "\n",
        "# v = VisualizeTransformer()\n",
        "# v.construct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n",
            "env: TORCH_USE_CUDA_DSA=1\n"
          ]
        }
      ],
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "%env TORCH_USE_CUDA_DSA=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 1],\n",
            "        [0, 2],\n",
            "        [0, 3],\n",
            "        [1, 0],\n",
            "        [1, 1],\n",
            "        [1, 2],\n",
            "        [1, 3],\n",
            "        [2, 0],\n",
            "        [2, 1],\n",
            "        [2, 2],\n",
            "        [2, 3],\n",
            "        [3, 0],\n",
            "        [3, 1],\n",
            "        [3, 2],\n",
            "        [3, 3]], device='cuda:0')\n",
            "tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
            "torch.Size([16, 2])\n",
            "tensor([], device='cuda:0', size=(0, 2), dtype=torch.int64)\n",
            "tensor([], device='cuda:0', dtype=torch.int64)\n",
            "torch.Size([0, 2])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0634f0b4a4834413a2a65041ef4c78d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 499 Train Loss 0.5683871473099118 Test Loss nan\n",
            "Epoch 999 Train Loss 0.17160392194173252 Test Loss nan\n",
            "Epoch 1499 Train Loss 0.08587255912178618 Test Loss nan\n",
            "Loss target 0.015625 reached with loss 0.015575607794261046 at epoch 1831\n",
            "Transposed Input:\n",
            " tensor([[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3],\n",
            "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]], device='cuda:0')\n",
            "Labels:  tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
            "Logits of last token:\n",
            " tensor([[  4.2765,  -2.9314],\n",
            "        [ -5.6699,   4.0113],\n",
            "        [ -3.0392,   2.1735],\n",
            "        [ 48.8298, -34.2855],\n",
            "        [  4.4201,  -3.0330],\n",
            "        [ -3.7969,   2.6920],\n",
            "        [ -3.0230,   2.1632],\n",
            "        [ 44.8129, -31.4579],\n",
            "        [-45.5796,  32.1872],\n",
            "        [ -1.2701,   0.9136],\n",
            "        [  1.8063,  -1.2344],\n",
            "        [ 32.7505, -22.9671],\n",
            "        [-28.0151,  19.8598],\n",
            "        [  1.5130,  -1.0457],\n",
            "        [  9.8084,  -6.8647],\n",
            "        [ -2.8223,   2.0899]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "Unembed:\n",
            " tensor([[-1.7863,  1.2884],\n",
            "        [-1.2537,  0.8602]], device='cuda:0')\n",
            "Last layer before unembed:\n",
            " tensor([[ -0.2843,  -3.0586],\n",
            "        [  1.5994,   2.1913],\n",
            "        [  1.0760,   0.8386],\n",
            "        [-12.7916, -20.7764],\n",
            "        [ -0.3337,  -3.1028],\n",
            "        [  1.0553,   1.4725],\n",
            "        [  1.0888,   0.8074],\n",
            "        [-11.6533, -19.1942],\n",
            "        [ 14.2328,  16.0253],\n",
            "        [  0.3418,   0.4736],\n",
            "        [ -0.2505,  -1.1364],\n",
            "        [ -8.2353, -14.4425],\n",
            "        [  9.8355,   8.2802],\n",
            "        [ -0.4497,  -0.6186],\n",
            "        [ -2.4784,  -4.3450],\n",
            "        [  2.1163,  -0.8167]], device='cuda:0')\n",
            "[[tensor([0.6768, 0.0113])(#FFFFFF), tensor([0.6768, 0.0113])(#58C4DD), tensor([-0.2410,  1.4154])(#FFFF00), tensor([-0.6591,  0.6833])(#FFFF00), tensor([-1.4354, -1.5261])(#58C4DD), tensor([-0.2410,  1.4154])(#FFFFFF), tensor([0.6768, 0.0113])(#58C4DD), tensor([-0.2410,  1.4154])(#FFFF00), tensor([-0.6591,  0.6833])(#FFFF00), tensor([-1.4354, -1.5261])(#58C4DD), tensor([-0.6591,  0.6833])(#FFFFFF), tensor([0.6768, 0.0113])(#FFFF00), tensor([-0.2410,  1.4154])(#FFFF00), tensor([-0.6591,  0.6833])(#58C4DD), tensor([-1.4354, -1.5261])(#58C4DD), tensor([-1.4354, -1.5261])(#FFFFFF), tensor([0.6768, 0.0113])(#FFFF00), tensor([-0.2410,  1.4154])(#58C4DD), tensor([-0.6591,  0.6833])(#58C4DD), tensor([-1.4354, -1.5261])(#FFFF00)], [tensor([-1.8987,  1.8099])(#FFFFFF), tensor([ 0.6370, -1.6276])(#58C4DD), tensor([-0.2808, -0.2235])(#FFFF00), tensor([-0.6989, -0.9556])(#FFFF00), tensor([-1.4752, -3.1650])(#58C4DD), tensor([-2.8165,  3.2140])(#FFFFFF), tensor([ 0.6370, -1.6276])(#58C4DD), tensor([-0.2808, -0.2235])(#FFFF00), tensor([-0.6989, -0.9556])(#FFFF00), tensor([-1.4752, -3.1650])(#58C4DD), tensor([-3.2346,  2.4819])(#FFFFFF), tensor([ 0.6370, -1.6276])(#FFFF00), tensor([-0.2808, -0.2235])(#FFFF00), tensor([-0.6989, -0.9556])(#58C4DD), tensor([-1.4752, -3.1650])(#58C4DD), tensor([-4.0109,  0.2725])(#FFFFFF), tensor([ 0.6370, -1.6276])(#FFFF00), tensor([-0.2808, -0.2235])(#58C4DD), tensor([-0.6989, -0.9556])(#58C4DD), tensor([-1.4752, -3.1650])(#FFFF00)], [tensor([10.9515, 18.9437])(#888888), tensor([-0.2843, -3.0586])(#58C4DD), tensor([1.5994, 2.1913])(#FFFF00), tensor([1.0760, 0.8386])(#FFFF00), tensor([-12.7916, -20.7764])(#58C4DD), tensor([18.8146, 32.2687])(#888888), tensor([-0.3337, -3.1028])(#58C4DD), tensor([1.0553, 1.4725])(#FFFF00), tensor([1.0888, 0.8074])(#FFFF00), tensor([-11.6533, -19.1942])(#58C4DD), tensor([15.5358, 27.0001])(#888888), tensor([14.2328, 16.0253])(#FFFF00), tensor([0.3418, 0.4736])(#FFFF00), tensor([-0.2505, -1.1364])(#58C4DD), tensor([ -8.2353, -14.4425])(#58C4DD), tensor([ 5.1952, 10.1895])(#888888), tensor([9.8355, 8.2802])(#FFFF00), tensor([-0.4497, -0.6186])(#58C4DD), tensor([-2.4784, -4.3450])(#58C4DD), tensor([ 2.1163, -0.8167])(#FFFF00)]]\n",
            "Labels:  ['00', '01', '02', '03', '10', '11', '12', '13', '20', '21', '22', '23', '30', '31', '32', '33']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Manim Community <span style=\"color: #008000; text-decoration-color: #008000\">v0.19.0</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Manim Community \u001b[32mv0.\u001b[0m\u001b[32m19.0\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "v= [[tensor([0.6768, 0.0113])(#FFFFFF), tensor([0.6768, 0.0113])(#58C4DD), tensor([-0.2410,  1.4154])(#FFFF00), tensor([-0.6591,  0.6833])(#FFFF00), tensor([-1.4354, -1.5261])(#58C4DD), tensor([-0.2410,  1.4154])(#FFFFFF), tensor([0.6768, 0.0113])(#58C4DD), tensor([-0.2410,  1.4154])(#FFFF00), tensor([-0.6591,  0.6833])(#FFFF00), tensor([-1.4354, -1.5261])(#58C4DD), tensor([-0.6591,  0.6833])(#FFFFFF), tensor([0.6768, 0.0113])(#FFFF00), tensor([-0.2410,  1.4154])(#FFFF00), tensor([-0.6591,  0.6833])(#58C4DD), tensor([-1.4354, -1.5261])(#58C4DD), tensor([-1.4354, -1.5261])(#FFFFFF), tensor([0.6768, 0.0113])(#FFFF00), tensor([-0.2410,  1.4154])(#58C4DD), tensor([-0.6591,  0.6833])(#58C4DD), tensor([-1.4354, -1.5261])(#FFFF00)], [tensor([-1.8987,  1.8099])(#FFFFFF), tensor([ 0.6370, -1.6276])(#58C4DD), tensor([-0.2808, -0.2235])(#FFFF00), tensor([-0.6989, -0.9556])(#FFFF00), tensor([-1.4752, -3.1650])(#58C4DD), tensor([-2.8165,  3.2140])(#FFFFFF), tensor([ 0.6370, -1.6276])(#58C4DD), tensor([-0.2808, -0.2235])(#FFFF00), tensor([-0.6989, -0.9556])(#FFFF00), tensor([-1.4752, -3.1650])(#58C4DD), tensor([-3.2346,  2.4819])(#FFFFFF), tensor([ 0.6370, -1.6276])(#FFFF00), tensor([-0.2808, -0.2235])(#FFFF00), tensor([-0.6989, -0.9556])(#58C4DD), tensor([-1.4752, -3.1650])(#58C4DD), tensor([-4.0109,  0.2725])(#FFFFFF), tensor([ 0.6370, -1.6276])(#FFFF00), tensor([-0.2808, -0.2235])(#58C4DD), tensor([-0.6989, -0.9556])(#58C4DD), tensor([-1.4752, -3.1650])(#FFFF00)], [tensor([10.9515, 18.9437])(#888888), tensor([-0.2843, -3.0586])(#58C4DD), tensor([1.5994, 2.1913])(#FFFF00), tensor([1.0760, 0.8386])(#FFFF00), tensor([-12.7916, -20.7764])(#58C4DD), tensor([18.8146, 32.2687])(#888888), tensor([-0.3337, -3.1028])(#58C4DD), tensor([1.0553, 1.4725])(#FFFF00), tensor([1.0888, 0.8074])(#FFFF00), tensor([-11.6533, -19.1942])(#58C4DD), tensor([15.5358, 27.0001])(#888888), tensor([14.2328, 16.0253])(#FFFF00), tensor([0.3418, 0.4736])(#FFFF00), tensor([-0.2505, -1.1364])(#58C4DD), tensor([ -8.2353, -14.4425])(#58C4DD), tensor([ 5.1952, 10.1895])(#888888), tensor([9.8355, 8.2802])(#FFFF00), tensor([-0.4497, -0.6186])(#58C4DD), tensor([-2.4784, -4.3450])(#58C4DD), tensor([ 2.1163, -0.8167])(#FFFF00)]]\n",
            "1.066122132539749 14.222222222222221 6.44785385131836 8.0 8.528977060317992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.242206735439848 18.718181440565317 33.75620594024659 10.528977060317992 55.19507446289063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unembed:  tensor([[-1.7863,  1.2884],\n",
            "        [-1.2537,  0.8602]], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                              \r"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video src=\"media/jupyter/Video@2025-01-30@09-21-29.mp4\" controls autoplay loop style=\"max-width: 80%;\"  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%manim -qh Video\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "\n",
        "\n",
        "input_dim = 4\n",
        "output_dim = 2\n",
        "train_data, train_labels, test_data, test_labels = get_training_data(input_dim, output_dim, data_seed=999)\n",
        "model = get_seeded_model(998, input_dim, output_dim)\n",
        "train_model(model, train_data, train_labels, test_data, test_labels, num_epochs = 10000, loss_target = 1/(input_dim ** 2 * 4))\n",
        "cache = create_cache(model)\n",
        "arrow_labels = [\"\".join([str(d.item()) for d in v]) for v in train_data]\n",
        "colors = [BLUE, YELLOW, GREEN, RED]\n",
        "arrow_colors = [colors[l] for l in train_labels]\n",
        "vectors = compile_data_vectors(cache, input_labels=arrow_labels, input_colors = arrow_colors)\n",
        "print(\"Labels: \", arrow_labels)\n",
        "\n",
        "class Video(VisualizeTransformer):\n",
        "    def construct(self):\n",
        "        VisualizeTransformer.construct(self)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
