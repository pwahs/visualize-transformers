{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpreting Identity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBvIU6zdIZpa"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ssx2pnTOIZpa"
      },
      "outputs": [],
      "source": [
        "TRAIN_MODEL = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7Jfz-lAWIZpb",
        "outputId": "48df1c71-5bc3-4a14-9a34-1af5c16786a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /home/pweiss/Research/.venv/lib/python3.12/site-packages (25.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_652075/1990858556.py:9: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
            "  ipython.magic(\"load_ext autoreload\")\n",
            "/tmp/ipykernel_652075/1990858556.py:10: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
            "  ipython.magic(\"autoreload 2\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipympl in /home/pweiss/Research/.venv/lib/python3.12/site-packages (0.9.6)\n",
            "Requirement already satisfied: ipython<9 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (8.31.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (8.1.5)\n",
            "Requirement already satisfied: matplotlib<4,>=3.5.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (3.10.0)\n",
            "Requirement already satisfied: numpy in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (2.2.2)\n",
            "Requirement already satisfied: pillow in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (11.1.0)\n",
            "Requirement already satisfied: traitlets<6 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipympl) (5.14.3)\n",
            "Requirement already satisfied: decorator in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (3.0.50)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (2.19.1)\n",
            "Requirement already satisfied: stack_data in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipython<9->ipympl) (0.6.3)\n",
            "Requirement already satisfied: comm>=0.1.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.2)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (2.9.0.post0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython<9->ipympl) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython<9->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython<9->ipympl) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from stack_data->ipython<9->ipympl) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from stack_data->ipython<9->ipympl) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from stack_data->ipython<9->ipympl) (0.2.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scipy in /home/pweiss/Research/.venv/lib/python3.12/site-packages (1.15.1)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from scipy) (2.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: manim in /home/pweiss/Research/.venv/lib/python3.12/site-packages (0.19.0)\n",
            "Requirement already satisfied: Pillow>=9.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (11.1.0)\n",
            "Requirement already satisfied: Pygments>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (2.19.1)\n",
            "Requirement already satisfied: av<14.0.0,>=9.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (13.1.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.12 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (4.12.3)\n",
            "Requirement already satisfied: click>=8.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (8.1.8)\n",
            "Requirement already satisfied: cloup>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (3.0.5)\n",
            "Requirement already satisfied: decorator>=4.3.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (5.1.1)\n",
            "Requirement already satisfied: isosurfaces>=0.1.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (0.1.2)\n",
            "Requirement already satisfied: manimpango<1.0.0,>=0.5.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (0.6.0)\n",
            "Requirement already satisfied: mapbox-earcut>=1.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (1.0.3)\n",
            "Requirement already satisfied: moderngl<6.0.0,>=5.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (5.12.0)\n",
            "Requirement already satisfied: moderngl-window>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.6 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (3.4.2)\n",
            "Requirement already satisfied: numpy>=2.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (2.2.2)\n",
            "Requirement already satisfied: pycairo<2.0.0,>=1.13 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (1.27.0)\n",
            "Requirement already satisfied: pydub>=0.20.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (0.25.1)\n",
            "Requirement already satisfied: rich>=12.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (13.9.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (1.15.1)\n",
            "Requirement already satisfied: screeninfo>=0.7 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (0.8.1)\n",
            "Requirement already satisfied: skia-pathops>=0.7.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (0.8.0.post2)\n",
            "Requirement already satisfied: srt>=3.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (3.5.3)\n",
            "Requirement already satisfied: svgelements>=1.8.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (1.9.6)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (4.12.2)\n",
            "Requirement already satisfied: watchdog>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from manim) (6.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from beautifulsoup4>=4.12->manim) (2.6)\n",
            "Requirement already satisfied: glcontext>=3.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from moderngl<6.0.0,>=5.0.0->manim) (3.0.0)\n",
            "Requirement already satisfied: pyglet>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from moderngl-window>=2.0.0->manim) (2.1.2)\n",
            "Requirement already satisfied: pyglm<3,>=2.7.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from moderngl-window>=2.0.0->manim) (2.7.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from rich>=12.0.0->manim) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->manim) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torch in /home/pweiss/Research/.venv/lib/python3.12/site-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (75.8.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "/bin/bash: Zeile 1: 2: Datei oder Verzeichnis nicht gefunden\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: einops in /home/pweiss/Research/.venv/lib/python3.12/site-packages (0.8.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: transformer_lens in /home/pweiss/Research/.venv/lib/python3.12/site-packages (2.11.0)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.14.1)\n",
            "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.0.3)\n",
            "Requirement already satisfied: datasets>=2.7.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (3.2.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.8.0)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.0.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.2.37)\n",
            "Requirement already satisfied: numpy>=1.26 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (2.2.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.10 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (2.6.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (4.48.1)\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (4.4.1)\n",
            "Requirement already satisfied: typing-extensions in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (4.12.2)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformer_lens) (0.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (24.2)\n",
            "Requirement already satisfied: psutil in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (6.1.1)\n",
            "Requirement already satisfied: pyyaml in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (0.28.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (0.5.2)\n",
            "Requirement already satisfied: filelock in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (19.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.11.11)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from jaxtyping>=0.2.11->transformer_lens) (0.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from rich>=12.6.0->transformer_lens) (2.19.1)\n",
            "Requirement already satisfied: networkx in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (75.8.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.10->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformers>=4.37.2->transformer_lens) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from transformers>=4.37.2->transformer_lens) (0.21.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (5.29.3)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (1.3.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.10->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/pweiss/Research/.venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "# Upgrade pip\n",
        "%pip install --upgrade pip\n",
        "\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "# Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "ipython.magic(\"load_ext autoreload\")\n",
        "ipython.magic(\"autoreload 2\")\n",
        "ipython.run_line_magic(\"pip\", \"install ipympl\")\n",
        "ipython.run_line_magic(\"pip\", \"install scipy\")\n",
        "ipython.run_line_magic(\"pip\", \"install manim\")\n",
        "ipython.run_line_magic(\"pip\", \"install torch\")\n",
        "ipython.run_line_magic(\"pip\", \"install numpy<2\")\n",
        "ipython.run_line_magic(\"pip\", \"install einops\")\n",
        "ipython.run_line_magic(\"pip\", \"install transformer_lens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i8GCNEdpIZpc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pweiss/Research/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n"
          ]
        }
      ],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import tqdm.auto as tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "import copy\n",
        "\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, ActivationCache\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "# Define the location to save the model, using a relative path\n",
        "PTH_LOCATION = \"workspace/_scratch/identity.pth\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(Path(PTH_LOCATION).parent, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M2Nzu7EIZpe"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOckI2-GIZpe"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_2OXlPG-IZpe"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = 3\n",
        "OUTPUT_DIM = 3\n",
        "frac_train = 1\n",
        "\n",
        "# Optimizer config\n",
        "lr = 1e-3\n",
        "wd = 1e-2\n",
        "betas = (0.9, 0.999)\n",
        "\n",
        "num_epochs = 10000\n",
        "checkpoint_every = 500\n",
        "\n",
        "DATA_SEED = 599"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT7xY9WsIZpe"
      },
      "source": [
        "## Define Task\n",
        "* Define random function\n",
        "* Define the dataset & labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOJMbA26IZpe"
      },
      "source": [
        "Input format:\n",
        "|a|b|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I8Af2zLZIZpf",
        "outputId": "5075c607-e865-4b8c-90df-d2685d17ebb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 1],\n",
            "        [0, 2],\n",
            "        [1, 0],\n",
            "        [1, 1],\n",
            "        [1, 2],\n",
            "        [2, 0],\n",
            "        [2, 1],\n",
            "        [2, 2]])\n",
            "tensor([0, 1, 2, 1, 1, 0, 2, 2, 0])\n",
            "torch.Size([9, 2])\n",
            "tensor([], size=(0, 2), dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "torch.Size([0, 2])\n"
          ]
        }
      ],
      "source": [
        "def get_training_data(input_dim = INPUT_DIM, output_dim = OUTPUT_DIM, data_seed = DATA_SEED):\n",
        "    torch.manual_seed(data_seed)\n",
        "    a_vector = torch.arange(input_dim)\n",
        "    dataset = torch.cartesian_prod(a_vector, a_vector).to(device)\n",
        "\n",
        "    labels = torch.randint(0, output_dim, (dataset.shape[0],), device=device)\n",
        "    train_data = dataset\n",
        "    train_labels = labels\n",
        "    # For now no test data\n",
        "    test_data = dataset[0:0]\n",
        "    test_labels = labels[0:0]\n",
        "    print(train_data)\n",
        "    print(train_labels)\n",
        "    print(train_data.shape)\n",
        "    print(test_data[:5])\n",
        "    print(test_labels[:5])\n",
        "    print(test_data.shape)\n",
        "    return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = get_training_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_83i1bUkIZpf"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UL7gVZ9WIZpf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_seeded_model(seed = 999, input_dim = INPUT_DIM, output_dim = OUTPUT_DIM):\n",
        "    cfg = HookedTransformerConfig(\n",
        "        n_layers = 1,\n",
        "        n_heads = 1,\n",
        "        d_model = 2,\n",
        "        d_head = 2,\n",
        "        d_mlp = 1,\n",
        "        attn_only=False,\n",
        "        act_fn = \"relu\",\n",
        "        normalization_type=None,\n",
        "        d_vocab=input_dim,\n",
        "        d_vocab_out=output_dim,\n",
        "        n_ctx=2,\n",
        "        init_weights=True,\n",
        "        device=device,\n",
        "        seed = seed,\n",
        "    )\n",
        "    model = HookedTransformer(cfg)\n",
        "    # Biases are enabled by default\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"mlp.b_out\" in name:\n",
        "            param.requires_grad = False\n",
        "    return model\n",
        "\n",
        "model = get_seeded_model(seed = 993)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lctx1jAtIZpg"
      },
      "source": [
        "## Define Optimizer + Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 1],\n",
            "        [0, 2],\n",
            "        [1, 0],\n",
            "        [1, 1],\n",
            "        [1, 2],\n",
            "        [2, 0],\n",
            "        [2, 1],\n",
            "        [2, 2]])\n",
            "tensor([[[ 0.1324,  0.1346,  0.1444],\n",
            "         [-0.1453,  0.5954,  0.4067]],\n",
            "\n",
            "        [[ 0.1324,  0.1346,  0.1444],\n",
            "         [ 0.0021,  0.2391,  0.1825]],\n",
            "\n",
            "        [[ 0.1324,  0.1346,  0.1444],\n",
            "         [-0.3875,  0.3479,  0.1415]],\n",
            "\n",
            "        [[ 0.2610,  0.0929,  0.1536],\n",
            "         [-0.1282,  0.5130,  0.3495]],\n",
            "\n",
            "        [[ 0.2610,  0.0929,  0.1536],\n",
            "         [ 0.0193,  0.1562,  0.1249]],\n",
            "\n",
            "        [[ 0.2610,  0.0929,  0.1536],\n",
            "         [-0.3633,  0.2177,  0.0502]],\n",
            "\n",
            "        [[-0.0580, -0.1071, -0.0999],\n",
            "         [-0.1084,  0.7052,  0.5020]],\n",
            "\n",
            "        [[-0.0580, -0.1071, -0.0999],\n",
            "         [ 0.0397,  0.3555,  0.2830]],\n",
            "\n",
            "        [[-0.0580, -0.1071, -0.0999],\n",
            "         [-0.3493,  0.5255,  0.2887]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(train_data)\n",
        "print(model(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dJORAU_PIZpg",
        "outputId": "1c2b9f25-056e-4e0d-defc-0bd11586136d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1912, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
            "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
            "Uniform loss:\n",
            "2.1972245773362196\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=betas)\n",
        "def loss_fn(logits, labels):\n",
        "    if len(logits.shape)==3:\n",
        "        logits = logits[:, -1]\n",
        "    logits = logits.to(torch.float64)\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    correct_log_probs = log_probs.gather(dim=-1, index=labels[:, None])[:, 0]\n",
        "    return -correct_log_probs.mean()\n",
        "train_logits = model(train_data)\n",
        "train_loss = loss_fn(train_logits, train_labels)\n",
        "print(train_loss)\n",
        "test_logits = model(test_data)\n",
        "test_loss = loss_fn(test_logits, test_labels)\n",
        "print(test_loss)\n",
        "print(\"Uniform loss:\")\n",
        "print(np.log(INPUT_DIM * INPUT_DIM))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW9Q4bIcIZpg"
      },
      "source": [
        "## Actually Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj4h2LIRIZpg"
      },
      "source": [
        "**Weird Decision:** Training the model with full batch training rather than stochastic gradient descent. We do this so to make training smoother and reduce the number of slingshots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_stats(model):\n",
        "    # Extract the p 2-dimensional tensors, vector i is vec[:, i]\n",
        "    vec = model.W_U.data\n",
        "\n",
        "    # Function to compute the angle between two vectors\n",
        "    def compute_angle(v1, v2):\n",
        "        cos_theta = torch.dot(v1, v2) / (torch.norm(v1) * torch.norm(v2))\n",
        "        angle = torch.acos(cos_theta) * (180.0 / np.pi)\n",
        "        return angle\n",
        "\n",
        "    # Compute pairwise angles\n",
        "    # for i in range(vec.shape[1]):\n",
        "    #     for j in range(i+1, vec.shape[1]):\n",
        "    #         angle = compute_angle(vec[:, i], vec[:, j])\n",
        "    #         print(f\"Angle between {i} and {j}: {angle.item():.2f}°\")\n",
        "    #     print(f\"Norm of vector {i}: {torch.norm(vec[:, i]):.2f}\")\n",
        "\n",
        "print_stats(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c477d3a6463646deb7cf1de99bb0199a"
          ]
        },
        "id": "UsZLeCMeIZph",
        "outputId": "133f3502-ca28-490c-c030-f60b751dcd7b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22dff07908564aeb9781ba6d85afce50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 499 Train Loss 0.5963916712405357 Test Loss nan\n",
            "Epoch 999 Train Loss 0.21747547169961456 Test Loss nan\n",
            "Epoch 1499 Train Loss 0.008244498748145694 Test Loss nan\n",
            "Epoch 1999 Train Loss 0.0026728980357629602 Test Loss nan\n",
            "Epoch 2499 Train Loss 0.0012444408153213494 Test Loss nan\n",
            "Epoch 2999 Train Loss 0.0006981506849781179 Test Loss nan\n",
            "Epoch 3499 Train Loss 0.00043569503453585627 Test Loss nan\n",
            "Epoch 3999 Train Loss 0.00029152461820886315 Test Loss nan\n",
            "Epoch 4499 Train Loss 0.00019844385815571584 Test Loss nan\n",
            "Epoch 4999 Train Loss 0.00013990493860122004 Test Loss nan\n",
            "Epoch 5499 Train Loss 0.0001004295480539135 Test Loss nan\n",
            "Epoch 5999 Train Loss 7.31394082077081e-05 Test Loss nan\n",
            "Epoch 6499 Train Loss 5.3726162289120084e-05 Test Loss nan\n",
            "Epoch 6999 Train Loss 4.008409974102984e-05 Test Loss nan\n",
            "Epoch 7499 Train Loss 2.952947689677196e-05 Test Loss nan\n",
            "Epoch 7999 Train Loss 2.2238729522731337e-05 Test Loss nan\n",
            "Epoch 8499 Train Loss 1.6790130198897674e-05 Test Loss nan\n",
            "Epoch 8999 Train Loss 1.2663341036269958e-05 Test Loss nan\n",
            "Epoch 9499 Train Loss 9.587009134167442e-06 Test Loss nan\n",
            "Epoch 9999 Train Loss 7.195741123185141e-06 Test Loss nan\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, train_data, train_labels, test_data, test_labels, num_epochs = num_epochs, loss_target = None):\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(), lr=lr, weight_decay=wd, betas=betas\n",
        "    )\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    model_checkpoints = []\n",
        "    checkpoint_epochs = []\n",
        "    if TRAIN_MODEL:\n",
        "        for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "            train_logits = model(train_data)\n",
        "            train_loss = loss_fn(train_logits, train_labels)\n",
        "            train_loss.backward()\n",
        "            train_losses.append(train_loss.item())\n",
        "            if loss_target is not None and train_loss.item() < loss_target:\n",
        "                print(f\"Loss target {loss_target} reached with loss {train_loss.item()} at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.inference_mode():\n",
        "                test_logits = model(test_data)\n",
        "                test_loss = loss_fn(test_logits, test_labels)\n",
        "                test_losses.append(test_loss.item())\n",
        "\n",
        "            if ((epoch+1)%checkpoint_every)==0:\n",
        "                checkpoint_epochs.append(epoch)\n",
        "                model_checkpoints.append(copy.deepcopy(model.state_dict()))\n",
        "                print_stats(model)\n",
        "                print(f\"Epoch {epoch} Train Loss {train_loss.item()} Test Loss {test_loss.item()}\")\n",
        "    if TRAIN_MODEL:\n",
        "        torch.save(\n",
        "            {\n",
        "                \"model\":model.state_dict(),\n",
        "                \"config\": model.cfg,\n",
        "                \"checkpoints\": model_checkpoints,\n",
        "                \"checkpoint_epochs\": checkpoint_epochs,\n",
        "                \"test_losses\": test_losses,\n",
        "                \"train_losses\": train_losses,\n",
        "            },\n",
        "            PTH_LOCATION)\n",
        "\n",
        "train_model(\n",
        "    model, train_data, train_labels, test_data, test_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EzRKi7J7IZph"
      },
      "outputs": [],
      "source": [
        "if not TRAIN_MODEL:\n",
        "    cached_data = torch.load(PTH_LOCATION)\n",
        "    model.load_state_dict(cached_data['model'])\n",
        "    model_checkpoints = cached_data[\"checkpoints\"]\n",
        "    checkpoint_epochs = cached_data[\"checkpoint_epochs\"]\n",
        "    test_losses = cached_data['test_losses']\n",
        "    train_losses = cached_data['train_losses']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transposed Input:\n",
            " tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
            "        [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
            "Labels:  tensor([0, 1, 2, 1, 1, 0, 2, 2, 0])\n",
            "Logits of last token:\n",
            " tensor([[ 4.6067e+00, -7.3325e+00, -5.6263e+00],\n",
            "        [-1.2100e+00,  1.4056e+01, -1.1336e+00],\n",
            "        [-1.1399e+00, -2.5416e+01,  1.1703e+01],\n",
            "        [ 3.3368e-02,  1.1553e+01, -2.7741e+00],\n",
            "        [-5.9428e+00,  3.3759e+01,  1.7660e+00],\n",
            "        [ 6.2936e+00, -8.1738e+00, -8.6916e+00],\n",
            "        [-1.9211e+00, -1.6715e+01,  1.0390e+01],\n",
            "        [-3.8065e+00, -1.4896e+01,  1.3527e+01],\n",
            "        [ 6.0160e+00, -1.3005e+01, -6.5537e+00]], grad_fn=<SliceBackward0>)\n",
            "Unembed:\n",
            " tensor([[ 1.0326, -0.9932, -1.7193],\n",
            "        [ 0.0391, -1.7637,  0.5023]])\n",
            "Last layer before unembed:\n",
            " tensor([[  3.5075,   2.0904],\n",
            "        [ -1.7789,  -7.0596],\n",
            "        [ -2.5756,  15.7691],\n",
            "        [ -0.6035,  -6.3025],\n",
            "        [ -6.0298, -15.8371],\n",
            "        [  5.1582,   1.6378],\n",
            "        [ -3.1577,  11.1636],\n",
            "        [ -4.9834,  11.1604],\n",
            "        [  4.7776,   4.5915]])\n"
          ]
        }
      ],
      "source": [
        "def create_cache(model):\n",
        "    input = train_data\n",
        "    print(\"Transposed Input:\\n\", input.transpose(0, 1))\n",
        "    logits, cache = model.run_with_cache(input)\n",
        "    print(\"Labels: \", train_labels)\n",
        "    print(\"Logits of last token:\\n\", logits[:, -1, :])\n",
        "    print(\"Unembed:\\n\", model.W_U.data)\n",
        "    print(\"Last layer before unembed:\\n\", cache.cache_dict[\"blocks.0.hook_resid_post\"][:, -1, :])\n",
        "    return cache\n",
        "\n",
        "cache = create_cache(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'hook_embed': tensor([[[ 0.4180,  0.9027],\n",
              "          [ 0.4180,  0.9027]],\n",
              " \n",
              "         [[ 0.4180,  0.9027],\n",
              "          [-1.0277, -0.1865]],\n",
              " \n",
              "         [[ 0.4180,  0.9027],\n",
              "          [ 1.6651, -0.0442]],\n",
              " \n",
              "         [[-1.0277, -0.1865],\n",
              "          [ 0.4180,  0.9027]],\n",
              " \n",
              "         [[-1.0277, -0.1865],\n",
              "          [-1.0277, -0.1865]],\n",
              " \n",
              "         [[-1.0277, -0.1865],\n",
              "          [ 1.6651, -0.0442]],\n",
              " \n",
              "         [[ 1.6651, -0.0442],\n",
              "          [ 0.4180,  0.9027]],\n",
              " \n",
              "         [[ 1.6651, -0.0442],\n",
              "          [-1.0277, -0.1865]],\n",
              " \n",
              "         [[ 1.6651, -0.0442],\n",
              "          [ 1.6651, -0.0442]]]),\n",
              " 'hook_pos_embed': tensor([[[ 0.3340,  1.2297],\n",
              "          [-0.2243, -1.8267]],\n",
              " \n",
              "         [[ 0.3340,  1.2297],\n",
              "          [-0.2243, -1.8267]],\n",
              " \n",
              "         [[ 0.3340,  1.2297],\n",
              "          [-0.2243, -1.8267]],\n",
              " \n",
              "         [[ 0.3340,  1.2297],\n",
              "          [-0.2243, -1.8267]],\n",
              " \n",
              "         [[ 0.3340,  1.2297],\n",
              "          [-0.2243, -1.8267]],\n",
              " \n",
              "         [[ 0.3340,  1.2297],\n",
              "          [-0.2243, -1.8267]],\n",
              " \n",
              "         [[ 0.3340,  1.2297],\n",
              "          [-0.2243, -1.8267]],\n",
              " \n",
              "         [[ 0.3340,  1.2297],\n",
              "          [-0.2243, -1.8267]],\n",
              " \n",
              "         [[ 0.3340,  1.2297],\n",
              "          [-0.2243, -1.8267]]]),\n",
              " 'blocks.0.hook_resid_pre': tensor([[[ 0.7520,  2.1324],\n",
              "          [ 0.1936, -0.9240]],\n",
              " \n",
              "         [[ 0.7520,  2.1324],\n",
              "          [-1.2520, -2.0131]],\n",
              " \n",
              "         [[ 0.7520,  2.1324],\n",
              "          [ 1.4408, -1.8709]],\n",
              " \n",
              "         [[-0.6937,  1.0433],\n",
              "          [ 0.1936, -0.9240]],\n",
              " \n",
              "         [[-0.6937,  1.0433],\n",
              "          [-1.2520, -2.0131]],\n",
              " \n",
              "         [[-0.6937,  1.0433],\n",
              "          [ 1.4408, -1.8709]],\n",
              " \n",
              "         [[ 1.9991,  1.1855],\n",
              "          [ 0.1936, -0.9240]],\n",
              " \n",
              "         [[ 1.9991,  1.1855],\n",
              "          [-1.2520, -2.0131]],\n",
              " \n",
              "         [[ 1.9991,  1.1855],\n",
              "          [ 1.4408, -1.8709]]]),\n",
              " 'blocks.0.attn.hook_q': tensor([[[[ 0.9970, -2.7534]],\n",
              " \n",
              "          [[-1.2685, -0.1673]]],\n",
              " \n",
              " \n",
              "         [[[ 0.9970, -2.7534]],\n",
              " \n",
              "          [[-3.8694,  1.9213]]],\n",
              " \n",
              " \n",
              "         [[[ 0.9970, -2.7534]],\n",
              " \n",
              "          [[ 0.0728, -0.6954]]],\n",
              " \n",
              " \n",
              "         [[[-1.6039, -0.6648]],\n",
              " \n",
              "          [[-1.2685, -0.1673]]],\n",
              " \n",
              " \n",
              "         [[[-1.6039, -0.6648]],\n",
              " \n",
              "          [[-3.8694,  1.9213]]],\n",
              " \n",
              " \n",
              "         [[[-1.6039, -0.6648]],\n",
              " \n",
              "          [[ 0.0728, -0.6954]]],\n",
              " \n",
              " \n",
              "         [[[ 2.3383, -3.2815]],\n",
              " \n",
              "          [[-1.2685, -0.1673]]],\n",
              " \n",
              " \n",
              "         [[[ 2.3383, -3.2815]],\n",
              " \n",
              "          [[-3.8694,  1.9213]]],\n",
              " \n",
              " \n",
              "         [[[ 2.3383, -3.2815]],\n",
              " \n",
              "          [[ 0.0728, -0.6954]]]]),\n",
              " 'blocks.0.attn.hook_k': tensor([[[[-0.4920, -2.6984]],\n",
              " \n",
              "          [[-1.0226,  1.4203]]],\n",
              " \n",
              " \n",
              "         [[[-0.4920, -2.6984]],\n",
              " \n",
              "          [[ 1.7623,  2.3301]]],\n",
              " \n",
              " \n",
              "         [[[-0.4920, -2.6984]],\n",
              " \n",
              "          [[-4.5747,  3.3317]]],\n",
              " \n",
              " \n",
              "         [[[ 2.2929, -1.7886]],\n",
              " \n",
              "          [[-1.0226,  1.4203]]],\n",
              " \n",
              " \n",
              "         [[[ 2.2929, -1.7886]],\n",
              " \n",
              "          [[ 1.7623,  2.3301]]],\n",
              " \n",
              " \n",
              "         [[[ 2.2929, -1.7886]],\n",
              " \n",
              "          [[-4.5747,  3.3317]]],\n",
              " \n",
              " \n",
              "         [[[-4.0441, -0.7870]],\n",
              " \n",
              "          [[-1.0226,  1.4203]]],\n",
              " \n",
              " \n",
              "         [[[-4.0441, -0.7870]],\n",
              " \n",
              "          [[ 1.7623,  2.3301]]],\n",
              " \n",
              " \n",
              "         [[[-4.0441, -0.7870]],\n",
              " \n",
              "          [[-4.5747,  3.3317]]]]),\n",
              " 'blocks.0.attn.hook_v': tensor([[[[-5.3277, -3.5526]],\n",
              " \n",
              "          [[ 2.2963,  1.6886]]],\n",
              " \n",
              " \n",
              "         [[[-5.3277, -3.5526]],\n",
              " \n",
              "          [[ 4.9887,  4.7811]]],\n",
              " \n",
              " \n",
              "         [[[-5.3277, -3.5526]],\n",
              " \n",
              "          [[ 4.6860,  1.9171]]],\n",
              " \n",
              " \n",
              "         [[[-2.6353, -0.4601]],\n",
              " \n",
              "          [[ 2.2963,  1.6886]]],\n",
              " \n",
              " \n",
              "         [[[-2.6353, -0.4601]],\n",
              " \n",
              "          [[ 4.9887,  4.7811]]],\n",
              " \n",
              " \n",
              "         [[[-2.6353, -0.4601]],\n",
              " \n",
              "          [[ 4.6860,  1.9171]]],\n",
              " \n",
              " \n",
              "         [[[-2.9379, -3.3241]],\n",
              " \n",
              "          [[ 2.2963,  1.6886]]],\n",
              " \n",
              " \n",
              "         [[[-2.9379, -3.3241]],\n",
              " \n",
              "          [[ 4.9887,  4.7811]]],\n",
              " \n",
              " \n",
              "         [[[-2.9379, -3.3241]],\n",
              " \n",
              "          [[ 4.6860,  1.9171]]]]),\n",
              " 'blocks.0.attn.hook_attn_scores': tensor([[[[ 4.9068,    -inf],\n",
              "           [ 0.7604,  0.7492]]],\n",
              " \n",
              " \n",
              "         [[[ 4.9068,    -inf],\n",
              "           [-2.3198, -1.6563]]],\n",
              " \n",
              " \n",
              "         [[[ 4.9068,    -inf],\n",
              "           [ 1.3016, -1.8739]]],\n",
              " \n",
              " \n",
              "         [[[-1.7596,    -inf],\n",
              "           [-1.8450,  0.7492]]],\n",
              " \n",
              " \n",
              "         [[[-1.7596,    -inf],\n",
              "           [-8.7034, -1.6563]]],\n",
              " \n",
              " \n",
              "         [[[-1.7596,    -inf],\n",
              "           [ 0.9976, -1.8739]]],\n",
              " \n",
              " \n",
              "         [[[-4.8606,    -inf],\n",
              "           [ 3.7204,  0.7492]]],\n",
              " \n",
              " \n",
              "         [[[-4.8606,    -inf],\n",
              "           [ 9.9957, -1.6563]]],\n",
              " \n",
              " \n",
              "         [[[-4.8606,    -inf],\n",
              "           [ 0.1788, -1.8739]]]]),\n",
              " 'blocks.0.attn.hook_pattern': tensor([[[[1.0000e+00, 0.0000e+00],\n",
              "           [5.0281e-01, 4.9719e-01]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [3.3994e-01, 6.6006e-01]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [9.5990e-01, 4.0100e-02]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [6.9511e-02, 9.3049e-01]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [8.6916e-04, 9.9913e-01]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [9.4642e-01, 5.3584e-02]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [9.5126e-01, 4.8745e-02]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [9.9999e-01, 8.7015e-06]]],\n",
              " \n",
              " \n",
              "         [[[1.0000e+00, 0.0000e+00],\n",
              "           [8.8621e-01, 1.1379e-01]]]]),\n",
              " 'blocks.0.attn.hook_z': tensor([[[[-5.3277, -3.5526]],\n",
              " \n",
              "          [[-1.5371, -0.9468]]],\n",
              " \n",
              " \n",
              "         [[[-5.3277, -3.5526]],\n",
              " \n",
              "          [[ 1.4818,  1.9482]]],\n",
              " \n",
              " \n",
              "         [[[-5.3277, -3.5526]],\n",
              " \n",
              "          [[-4.9261, -3.3333]]],\n",
              " \n",
              " \n",
              "         [[[-2.6353, -0.4601]],\n",
              " \n",
              "          [[ 1.9535,  1.5392]]],\n",
              " \n",
              " \n",
              "         [[[-2.6353, -0.4601]],\n",
              " \n",
              "          [[ 4.9820,  4.7766]]],\n",
              " \n",
              " \n",
              "         [[[-2.6353, -0.4601]],\n",
              " \n",
              "          [[-2.2430, -0.3327]]],\n",
              " \n",
              " \n",
              "         [[[-2.9379, -3.3241]],\n",
              " \n",
              "          [[-2.6828, -3.0798]]],\n",
              " \n",
              " \n",
              "         [[[-2.9379, -3.3241]],\n",
              " \n",
              "          [[-2.9378, -3.3241]]],\n",
              " \n",
              " \n",
              "         [[[-2.9379, -3.3241]],\n",
              " \n",
              "          [[-2.0704, -2.7277]]]]),\n",
              " 'blocks.0.hook_attn_out': tensor([[[  7.7421,  12.0274],\n",
              "          [  3.3138,   3.0144]],\n",
              " \n",
              "         [[  7.7421,  12.0274],\n",
              "          [ -0.5269,  -5.0465]],\n",
              " \n",
              "         [[  7.7421,  12.0274],\n",
              "          [  7.2948,  11.1337]],\n",
              " \n",
              "         [[  4.1212,   4.2883],\n",
              "          [ -0.7971,  -5.3785]],\n",
              " \n",
              "         [[  4.1212,   4.2883],\n",
              "          [ -4.7778, -13.8240]],\n",
              " \n",
              "         [[  4.1212,   4.2883],\n",
              "          [  3.7174,   3.5088]],\n",
              " \n",
              "         [[  5.4920,   7.8684],\n",
              "          [  5.1675,   7.1875]],\n",
              " \n",
              "         [[  5.4920,   7.8684],\n",
              "          [  5.4919,   7.8682]],\n",
              " \n",
              "         [[  5.4920,   7.8684],\n",
              "          [  4.4786,   5.8056]]]),\n",
              " 'blocks.0.hook_resid_mid': tensor([[[  8.4941,  14.1598],\n",
              "          [  3.5075,   2.0904]],\n",
              " \n",
              "         [[  8.4941,  14.1598],\n",
              "          [ -1.7789,  -7.0596]],\n",
              " \n",
              "         [[  8.4941,  14.1598],\n",
              "          [  8.7355,   9.2628]],\n",
              " \n",
              "         [[  3.4275,   5.3315],\n",
              "          [ -0.6035,  -6.3025]],\n",
              " \n",
              "         [[  3.4275,   5.3315],\n",
              "          [ -6.0298, -15.8371]],\n",
              " \n",
              "         [[  3.4275,   5.3315],\n",
              "          [  5.1582,   1.6378]],\n",
              " \n",
              "         [[  7.4911,   9.0539],\n",
              "          [  5.3612,   6.2634]],\n",
              " \n",
              "         [[  7.4911,   9.0539],\n",
              "          [  4.2399,   5.8550]],\n",
              " \n",
              "         [[  7.4911,   9.0539],\n",
              "          [  5.9193,   3.9347]]]),\n",
              " 'blocks.0.mlp.hook_pre': tensor([[[ 9.8860e+00],\n",
              "          [-8.9670e-03]],\n",
              " \n",
              "         [[ 9.8860e+00],\n",
              "          [-6.5458e+00]],\n",
              " \n",
              "         [[ 9.8860e+00],\n",
              "          [ 4.4205e+00]],\n",
              " \n",
              "         [[ 3.5573e+00],\n",
              "          [-6.4776e+00]],\n",
              " \n",
              "         [[ 3.5573e+00],\n",
              "          [-1.3342e+01]],\n",
              " \n",
              "         [[ 3.5573e+00],\n",
              "          [-1.5572e+00]],\n",
              " \n",
              "         [[ 4.9911e+00],\n",
              "          [ 3.3293e+00]],\n",
              " \n",
              "         [[ 4.9911e+00],\n",
              "          [ 3.6046e+00]],\n",
              " \n",
              "         [[ 4.9911e+00],\n",
              "          [ 4.4622e-01]]]),\n",
              " 'blocks.0.mlp.hook_post': tensor([[[9.8860],\n",
              "          [0.0000]],\n",
              " \n",
              "         [[9.8860],\n",
              "          [0.0000]],\n",
              " \n",
              "         [[9.8860],\n",
              "          [4.4205]],\n",
              " \n",
              "         [[3.5573],\n",
              "          [0.0000]],\n",
              " \n",
              "         [[3.5573],\n",
              "          [0.0000]],\n",
              " \n",
              "         [[3.5573],\n",
              "          [0.0000]],\n",
              " \n",
              "         [[4.9911],\n",
              "          [3.3293]],\n",
              " \n",
              "         [[4.9911],\n",
              "          [3.6046]],\n",
              " \n",
              "         [[4.9911],\n",
              "          [0.4462]]]),\n",
              " 'blocks.0.hook_mlp_out': tensor([[[-25.2961,  14.5507],\n",
              "          [  0.0000,   0.0000]],\n",
              " \n",
              "         [[-25.2961,  14.5507],\n",
              "          [  0.0000,   0.0000]],\n",
              " \n",
              "         [[-25.2961,  14.5507],\n",
              "          [-11.3111,   6.5063]],\n",
              " \n",
              "         [[ -9.1023,   5.2358],\n",
              "          [  0.0000,   0.0000]],\n",
              " \n",
              "         [[ -9.1023,   5.2358],\n",
              "          [  0.0000,   0.0000]],\n",
              " \n",
              "         [[ -9.1023,   5.2358],\n",
              "          [  0.0000,   0.0000]],\n",
              " \n",
              "         [[-12.7711,   7.3461],\n",
              "          [ -8.5189,   4.9002]],\n",
              " \n",
              "         [[-12.7711,   7.3461],\n",
              "          [ -9.2233,   5.3054]],\n",
              " \n",
              "         [[-12.7711,   7.3461],\n",
              "          [ -1.1418,   0.6568]]]),\n",
              " 'blocks.0.hook_resid_post': tensor([[[-16.8020,  28.7105],\n",
              "          [  3.5075,   2.0904]],\n",
              " \n",
              "         [[-16.8020,  28.7105],\n",
              "          [ -1.7789,  -7.0596]],\n",
              " \n",
              "         [[-16.8020,  28.7105],\n",
              "          [ -2.5756,  15.7691]],\n",
              " \n",
              "         [[ -5.6748,  10.5673],\n",
              "          [ -0.6035,  -6.3025]],\n",
              " \n",
              "         [[ -5.6748,  10.5673],\n",
              "          [ -6.0298, -15.8371]],\n",
              " \n",
              "         [[ -5.6748,  10.5673],\n",
              "          [  5.1582,   1.6378]],\n",
              " \n",
              "         [[ -5.2799,  16.3999],\n",
              "          [ -3.1577,  11.1636]],\n",
              " \n",
              "         [[ -5.2799,  16.3999],\n",
              "          [ -4.9834,  11.1604]],\n",
              " \n",
              "         [[ -5.2799,  16.3999],\n",
              "          [  4.7776,   4.5915]]])}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get a list of all activations stored in the cache, especially their names\n",
        "cache.cache_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Animations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pweiss/Research/.venv/lib/python3.12/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
            "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
          ]
        }
      ],
      "source": [
        "from manim import *\n",
        "\n",
        "config.media_width = \"80%\"\n",
        "config.verbosity = \"WARNING\"\n",
        "config.preview = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[tensor([0.4180, 0.9027])(#FFFFFF)], [tensor([0.7520, 2.1324])(#FFFFFF)], [tensor([ 8.4941, 14.1598])(#888888)], [tensor([-16.8020,  28.7105])(#888888)]]\n"
          ]
        }
      ],
      "source": [
        "class VectorParams:\n",
        "    def __init__(self, values = [], color = WHITE, label = \"\"):\n",
        "        self.values = values\n",
        "        self.color = color\n",
        "        self.label = label\n",
        "    def __repr__(self) -> str:\n",
        "        return str(self.values) + \"(\" + str(self.color) + \")\"\n",
        "\n",
        "class Data:\n",
        "    def __init__(self):\n",
        "        self.vectors: list[list[VectorParams]] = [[]]\n",
        "        self.steps = 0\n",
        "        self.current_labels = set()\n",
        "\n",
        "    def add_vector(self, vector, color = WHITE, label = \"\"):\n",
        "        if label not in self.current_labels:\n",
        "            self.current_labels.add(label)\n",
        "            self.vectors[self.steps].append(VectorParams(values = vector, color = color, label = label))\n",
        "\n",
        "    def next_step(self):\n",
        "        self.steps += 1\n",
        "        self.vectors.append([])\n",
        "        self.current_labels = set()\n",
        "\n",
        "    def add_vectors_at_hook(self, c: ActivationCache, hook: str, color0 = WHITE, color1 = WHITE, input_labels = None, input_colors = None):\n",
        "        if input_labels is None:\n",
        "            input_labels = [\"\" for i in range(c.cache_dict[hook].shape[0])]\n",
        "        for i in range(c.cache_dict[hook].shape[0]):\n",
        "            self.add_vector(c.cache_dict[hook][i][0].cpu(), color = color0, label = input_labels[i][:1])\n",
        "            self.add_vector(\n",
        "                c.cache_dict[hook][i][1].cpu(), color=color1 if input_colors is None else input_colors[i], label=input_labels[i][:2]\n",
        "            )\n",
        "\n",
        "\n",
        "def compile_data_vectors(cache, input_labels=None, input_colors=None):\n",
        "    # Set default value as list of empty strings\n",
        "    vectors = Data()\n",
        "    vectors.add_vectors_at_hook(cache, \"hook_embed\", color1 = GRAY, input_labels=input_labels, input_colors=input_colors)\n",
        "    vectors.next_step()\n",
        "    vectors.add_vectors_at_hook(cache, \"blocks.0.hook_resid_pre\", input_labels=input_labels, input_colors=input_colors)\n",
        "    vectors.next_step()\n",
        "    vectors.add_vectors_at_hook(cache, \"blocks.0.hook_resid_mid\", color0 = GRAY, input_labels=input_labels, input_colors=input_colors)\n",
        "    vectors.next_step()\n",
        "    vectors.add_vectors_at_hook(cache, \"blocks.0.hook_resid_post\", color0 = GRAY, input_labels=input_labels, input_colors=input_colors)\n",
        "    \n",
        "    print(vectors.vectors)\n",
        "    return vectors\n",
        "\n",
        "\n",
        "vectors = compile_data_vectors(cache)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def change_font_size(labeled_arrow: LabeledArrow, new_size):\n",
        "    # print(labeled_arrow, labeled_arrow.submobjects)\n",
        "    # print(labeled_arrow.submobjects[-1].font_size)\n",
        "    if not isinstance(labeled_arrow, LabeledArrow):\n",
        "        return\n",
        "    label = labeled_arrow.submobjects[-1]\n",
        "    box = labeled_arrow.submobjects[-2]\n",
        "    if not isinstance(box, BackgroundRectangle):\n",
        "        box = labeled_arrow.submobjects[-3]\n",
        "    coords = label.get_center()\n",
        "    # print(new_size)\n",
        "    labeled_arrow.submobjects[-1] = MathTex(\n",
        "        label.get_tex_string(), color=label.color, font_size=new_size\n",
        "    )\n",
        "    # print(\"size=\", labeled_arrow.submobjects[-1].font_size)\n",
        "    label = labeled_arrow.submobjects[-1]\n",
        "    label.move_to(coords)\n",
        "    box.width = label.width + 2 * box.buff\n",
        "    box.height = label.height + 2 * box.buff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "DOT_SCALE = 0.01\n",
        "class VisualizeTransformer(MovingCameraScene):\n",
        "    def construct(self):\n",
        "        print(\"v=\", vectors.vectors)\n",
        "        axes = Axes(\n",
        "            x_range = [-20, 20, 1],\n",
        "            y_range = [-20, 20, 1],\n",
        "            x_axis_config={\n",
        "                \"numbers_to_include\": np.arange(-18, 18.1, 3),\n",
        "                \"font_size\": 24\n",
        "            },\n",
        "            y_axis_config={\n",
        "                \"numbers_to_include\": np.arange(-18, 18.1, 3), \n",
        "                \"font_size\": 24            \n",
        "            },\n",
        "            x_length = 40,\n",
        "            y_length = 40,\n",
        "            axis_config={\"color\": GREEN}\n",
        "        )\n",
        "\n",
        "        scale = ValueTracker(2)\n",
        "\n",
        "        dots = VGroup()\n",
        "        def update_scale(self):\n",
        "            return\n",
        "            # TODO: Make the scaling nicer\n",
        "            self.stroke_width = 6 * scale.get_value()\n",
        "            change_font_size(self, 48 * scale.get_value())\n",
        "            # print(\"New font size: \", self.font_size)\n",
        "\n",
        "        # Embedding arrows\n",
        "        for i, t in enumerate(vectors.vectors[0]):\n",
        "            # print(t, t.numpy())\n",
        "            # arrow = LabeledArrow(\n",
        "            #     start=ORIGIN,\n",
        "            #     end=np.append(t.values.numpy(), 0),\n",
        "            #     buff = 0,\n",
        "            #     label = t.label,\n",
        "            #     label_frame = False,\n",
        "            #     label_color=YELLOW,\n",
        "            #     color = t.color,\n",
        "            #     max_stroke_width_to_length_ratio = 100,\n",
        "            # )\n",
        "\n",
        "            # arrow.add_updater(update_scale)\n",
        "            # arrows.add(arrow)\n",
        "            dot = LabeledDot(\n",
        "                point=np.append(t.values.numpy(), 0),\n",
        "                label=t.label,\n",
        "                color=t.color,\n",
        "                radius=DOT_SCALE * (len(vectors.vectors[0]) - i) + 0.2,\n",
        "            )\n",
        "\n",
        "            dot.set_opacity(0.5)\n",
        "\n",
        "            dot.add_updater(update_scale)\n",
        "            dots.add(dot)\n",
        "\n",
        "        # Transitioning the arrows through the model\n",
        "        self.add(axes, axes.get_axis_labels(), dots)\n",
        "        for step in range(1, len(vectors.vectors)):\n",
        "            new_dots = VGroup()\n",
        "            transition_arrows = VGroup()\n",
        "            for i, t in enumerate(vectors.vectors[step]):\n",
        "                # print(t, t.numpy())\n",
        "                # new_arrow = LabeledArrow(\n",
        "                #     start=ORIGIN,\n",
        "                #     end=np.append(t.values.numpy(), 0),\n",
        "                #     buff=0,\n",
        "                #     label=t.label,\n",
        "                #     label_frame=False,\n",
        "                #     label_color=YELLOW,\n",
        "                #     color=t.color,\n",
        "                #     max_stroke_width_to_length_ratio=100,\n",
        "                # )\n",
        "                # new_arrow.add_updater(update_scale)\n",
        "                # new_arrows.add(new_arrow)\n",
        "                new_dot = LabeledDot(\n",
        "                    point=np.append(t.values.numpy(), 0),\n",
        "                    label=t.label,\n",
        "                    color=t.color,\n",
        "                    radius = DOT_SCALE * (len(vectors.vectors[step]) - i) + 0.2,\n",
        "                )\n",
        "                new_dot.set_opacity(0.5)\n",
        "                new_dot.add_updater(update_scale)\n",
        "                new_dots.add(new_dot)\n",
        "\n",
        "                transition_arrow = Arrow(\n",
        "                    start=dots[i].arc_center,\n",
        "                    end=new_dots[i].arc_center,\n",
        "                    buff=0,\n",
        "                    color=RED,\n",
        "                )\n",
        "                transition_arrow.add_updater(update_scale)\n",
        "                transition_arrows.add(transition_arrow)\n",
        "\n",
        "            view = SurroundingRectangle(new_dots)\n",
        "            factor = max(\n",
        "                view.width / self.camera.frame_width,\n",
        "                view.height / self.camera.frame_height,\n",
        "            )\n",
        "            print(\n",
        "                factor,\n",
        "                self.camera.frame_width, view.width,\n",
        "                self.camera.frame_height, view.height,\n",
        "            )\n",
        "            self.wait()\n",
        "            self.play(FadeIn(transition_arrows), self.camera.auto_zoom(view, margin = 2), scale.animate.set_value(scale.get_value() * factor))\n",
        "            self.wait()\n",
        "            self.play(\n",
        "                ReplacementTransform(dots, new_dots)\n",
        "            )\n",
        "            self.wait()\n",
        "            self.play(FadeOut(transition_arrows))\n",
        "            self.wait()\n",
        "            dots = new_dots\n",
        "\n",
        "        # Unembedding Arrows\n",
        "        embedding_arrows = VGroup()\n",
        "        data = model.W_U.data\n",
        "        print(\"unembed: \", data)\n",
        "        for i in range(data.size()[1]):\n",
        "            embedding_arrow = LabeledArrow(\n",
        "                start=ORIGIN,\n",
        "                end=[data[0, i].item(), data[1, i].item(), 0],\n",
        "                label=str(i),\n",
        "                color=LIGHT_PINK,\n",
        "                buff=0,\n",
        "                max_stroke_width_to_length_ratio=100,\n",
        "            )\n",
        "            embedding_arrows.add(embedding_arrow)\n",
        "        self.play(FadeIn(embedding_arrows))\n",
        "        self.wait()\n",
        "\n",
        "# v = VisualizeTransformer()\n",
        "# v.construct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n",
            "env: TORCH_USE_CUDA_DSA=1\n"
          ]
        }
      ],
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "%env TORCH_USE_CUDA_DSA=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 1],\n",
            "        [0, 2],\n",
            "        [0, 3],\n",
            "        [1, 0],\n",
            "        [1, 1],\n",
            "        [1, 2],\n",
            "        [1, 3],\n",
            "        [2, 0],\n",
            "        [2, 1],\n",
            "        [2, 2],\n",
            "        [2, 3],\n",
            "        [3, 0],\n",
            "        [3, 1],\n",
            "        [3, 2],\n",
            "        [3, 3]])\n",
            "tensor([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
            "torch.Size([16, 2])\n",
            "tensor([], size=(0, 2), dtype=torch.int64)\n",
            "tensor([], dtype=torch.int64)\n",
            "torch.Size([0, 2])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c776b514af44f0fb79a29da24fad0aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 499 Train Loss 0.41370474859541106 Test Loss nan\n",
            "Epoch 999 Train Loss 0.21454377600874963 Test Loss nan\n",
            "Epoch 1499 Train Loss 0.08929511159139729 Test Loss nan\n",
            "Epoch 1999 Train Loss 0.0873764823601811 Test Loss nan\n",
            "Epoch 2499 Train Loss 0.08700525877129292 Test Loss nan\n",
            "Epoch 2999 Train Loss 0.08686360368017351 Test Loss nan\n",
            "Epoch 3499 Train Loss 0.08679235683343546 Test Loss nan\n",
            "Epoch 3999 Train Loss 0.08675086852883909 Test Loss nan\n",
            "Epoch 4499 Train Loss 0.08672390230506992 Test Loss nan\n",
            "Epoch 4999 Train Loss 0.08670552669529044 Test Loss nan\n",
            "Epoch 5499 Train Loss 0.08669331189140848 Test Loss nan\n",
            "Epoch 5999 Train Loss 0.08668164177630497 Test Loss nan\n",
            "Epoch 6499 Train Loss 0.08667355192831118 Test Loss nan\n",
            "Epoch 6999 Train Loss 0.08666749664564917 Test Loss nan\n",
            "Epoch 7499 Train Loss 0.0866627468616861 Test Loss nan\n",
            "Epoch 7999 Train Loss 0.08665908031492568 Test Loss nan\n",
            "Epoch 8499 Train Loss 0.08665586884163146 Test Loss nan\n",
            "Epoch 8999 Train Loss 0.08665372916823677 Test Loss nan\n",
            "Epoch 9499 Train Loss 0.08665161411162291 Test Loss nan\n",
            "Epoch 9999 Train Loss 0.0867012086530944 Test Loss nan\n",
            "Epoch 10499 Train Loss 0.08664915653263257 Test Loss nan\n",
            "Epoch 10999 Train Loss 0.08664809114714551 Test Loss nan\n",
            "Epoch 11499 Train Loss 0.08664706942221155 Test Loss nan\n",
            "Epoch 11999 Train Loss 0.08664648419917355 Test Loss nan\n",
            "Epoch 12499 Train Loss 0.08664607210151194 Test Loss nan\n",
            "Epoch 12999 Train Loss 0.08664579053863866 Test Loss nan\n",
            "Epoch 13499 Train Loss 0.08666524881531029 Test Loss nan\n",
            "Epoch 13999 Train Loss 0.08664502082313494 Test Loss nan\n",
            "Epoch 14499 Train Loss 0.08664459515698451 Test Loss nan\n",
            "Epoch 14999 Train Loss 0.08664441800587805 Test Loss nan\n",
            "Epoch 15499 Train Loss 0.08664429897542315 Test Loss nan\n",
            "Epoch 15999 Train Loss 0.0866443295228873 Test Loss nan\n",
            "Epoch 16499 Train Loss 0.08664415707503194 Test Loss nan\n",
            "Epoch 16999 Train Loss 0.08664842258766663 Test Loss nan\n",
            "Epoch 17499 Train Loss 0.08665045856697333 Test Loss nan\n",
            "Epoch 17999 Train Loss 0.08664398022620623 Test Loss nan\n",
            "Epoch 18499 Train Loss 0.08664409259225639 Test Loss nan\n",
            "Epoch 18999 Train Loss 0.08664391936144467 Test Loss nan\n",
            "Epoch 19499 Train Loss 0.08664395003829366 Test Loss nan\n",
            "Epoch 19999 Train Loss 0.08664406430352199 Test Loss nan\n",
            "Transposed Input:\n",
            " tensor([[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3],\n",
            "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]])\n",
            "Labels:  tensor([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
            "Logits of last token:\n",
            " tensor([[ 16.4337, -19.6609],\n",
            "        [  6.4392,  -7.6660],\n",
            "        [ -8.0949,  10.0715],\n",
            "        [ -6.7636,   8.2564],\n",
            "        [  8.9009, -10.5445],\n",
            "        [ -6.8833,   8.3990],\n",
            "        [ -5.2490,   8.8977],\n",
            "        [ -5.2349,   8.4905],\n",
            "        [ -6.6208,   8.0905],\n",
            "        [  0.2263,   0.2230],\n",
            "        [ 11.8017,  -4.4950],\n",
            "        [ -3.3080,   9.9354],\n",
            "        [ -6.2394,   7.5845],\n",
            "        [  0.2263,   0.2230],\n",
            "        [ 10.1557,  -3.4503],\n",
            "        [ 10.0832,  -3.7690]], grad_fn=<SliceBackward0>)\n",
            "Unembed:\n",
            " tensor([[-1.4806,  2.1872],\n",
            "        [ 1.3179, -0.9218]])\n",
            "Last layer before unembed:\n",
            " tensor([[-7.2286,  4.7477],\n",
            "        [-2.8831,  2.0460],\n",
            "        [ 3.6919, -1.5957],\n",
            "        [ 2.9243, -1.4479],\n",
            "        [-3.8875,  2.7854],\n",
            "        [ 2.9755, -1.4812],\n",
            "        [ 4.4013,  1.3608],\n",
            "        [ 4.0562,  0.9838],\n",
            "        [ 2.8670, -1.4039],\n",
            "        [ 0.1939,  0.7885],\n",
            "        [ 3.1282, 12.8687],\n",
            "        [ 6.4815,  5.1709],\n",
            "        [ 2.6593, -1.3478],\n",
            "        [ 0.1939,  0.7885],\n",
            "        [ 3.0355, 11.5156],\n",
            "        [ 2.7147, 11.1002]])\n",
            "[[tensor([-0.7126, -1.4422])(#FFFFFF), tensor([-0.7126, -1.4422])(#58C4DD), tensor([ 0.4653, -0.5544])(#58C4DD), tensor([1.7884, 2.3283])(#FFFF00), tensor([1.4434, 1.9512])(#FFFF00), tensor([ 0.4653, -0.5544])(#FFFFFF), tensor([-0.7126, -1.4422])(#58C4DD), tensor([ 0.4653, -0.5544])(#FFFF00), tensor([1.7884, 2.3283])(#FFFF00), tensor([1.4434, 1.9512])(#FFFF00), tensor([1.7884, 2.3283])(#FFFFFF), tensor([-0.7126, -1.4422])(#FFFF00), tensor([ 0.4653, -0.5544])(#FFFF00), tensor([1.7884, 2.3283])(#58C4DD), tensor([1.4434, 1.9512])(#FFFF00), tensor([1.4434, 1.9512])(#FFFFFF), tensor([-0.7126, -1.4422])(#FFFF00), tensor([ 0.4653, -0.5544])(#58C4DD), tensor([1.7884, 2.3283])(#58C4DD), tensor([1.4434, 1.9512])(#58C4DD)], [tensor([-1.4972, -0.7341])(#FFFFFF), tensor([ 0.3471, -1.7870])(#58C4DD), tensor([ 1.5250, -0.8991])(#58C4DD), tensor([2.8482, 1.9835])(#FFFF00), tensor([2.5031, 1.6065])(#FFFF00), tensor([-0.3193,  0.1537])(#FFFFFF), tensor([ 0.3471, -1.7870])(#58C4DD), tensor([ 1.5250, -0.8991])(#FFFF00), tensor([2.8482, 1.9835])(#FFFF00), tensor([2.5031, 1.6065])(#FFFF00), tensor([1.0038, 3.0363])(#FFFFFF), tensor([ 0.3471, -1.7870])(#FFFF00), tensor([ 1.5250, -0.8991])(#FFFF00), tensor([2.8482, 1.9835])(#58C4DD), tensor([2.5031, 1.6065])(#FFFF00), tensor([0.6587, 2.6593])(#FFFFFF), tensor([ 0.3471, -1.7870])(#FFFF00), tensor([ 1.5250, -0.8991])(#58C4DD), tensor([2.8482, 1.9835])(#58C4DD), tensor([2.5031, 1.6065])(#58C4DD)], [tensor([-0.6535, -4.3134])(#888888), tensor([ 2.2258, -6.9975])(#58C4DD), tensor([ 2.3687, -4.4783])(#58C4DD), tensor([ 3.6919, -1.5957])(#FFFF00), tensor([ 3.3468, -1.9727])(#FFFF00), tensor([ 1.2338, -0.4690])(#888888), tensor([ 3.1111, -5.9089])(#58C4DD), tensor([ 3.3383, -1.9320])(#FFFF00), tensor([4.4013, 1.3608])(#FFFF00), tensor([4.0562, 0.9838])(#FFFF00), tensor([ 1.2698, 13.9438])(#888888), tensor([ 2.8670, -1.4039])(#FFFF00), tensor([ 6.8894, -7.5293])(#FFFF00), tensor([ 3.1282, 12.8687])(#58C4DD), tensor([6.4815, 5.1709])(#FFFF00), tensor([ 0.8461, 12.1914])(#888888), tensor([ 2.6593, -1.3478])(#FFFF00), tensor([ 6.8894, -7.5293])(#58C4DD), tensor([ 3.0355, 11.5156])(#58C4DD), tensor([ 2.7147, 11.1002])(#58C4DD)], [tensor([-7.9849,  4.7945])(#888888), tensor([-7.2286,  4.7477])(#58C4DD), tensor([-2.8831,  2.0460])(#58C4DD), tensor([ 3.6919, -1.5957])(#FFFF00), tensor([ 2.9243, -1.4479])(#FFFF00), tensor([ 1.2338, -0.4690])(#888888), tensor([-3.8875,  2.7854])(#58C4DD), tensor([ 2.9755, -1.4812])(#FFFF00), tensor([4.4013, 1.3608])(#FFFF00), tensor([4.0562, 0.9838])(#FFFF00), tensor([ 1.2698, 13.9438])(#888888), tensor([ 2.8670, -1.4039])(#FFFF00), tensor([0.1939, 0.7885])(#FFFF00), tensor([ 3.1282, 12.8687])(#58C4DD), tensor([6.4815, 5.1709])(#FFFF00), tensor([ 0.8461, 12.1914])(#888888), tensor([ 2.6593, -1.3478])(#FFFF00), tensor([0.1939, 0.7885])(#58C4DD), tensor([ 3.0355, 11.5156])(#58C4DD), tensor([ 2.7147, 11.1002])(#58C4DD)]]\n",
            "Labels:  ['00', '01', '02', '03', '10', '11', '12', '13', '20', '21', '22', '23', '30', '31', '32', '33']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Manim Community <span style=\"color: #008000; text-decoration-color: #008000\">v0.19.0</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Manim Community \u001b[32mv0.\u001b[0m\u001b[32m19.0\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "v= [[tensor([-0.7126, -1.4422])(#FFFFFF), tensor([-0.7126, -1.4422])(#58C4DD), tensor([ 0.4653, -0.5544])(#58C4DD), tensor([1.7884, 2.3283])(#FFFF00), tensor([1.4434, 1.9512])(#FFFF00), tensor([ 0.4653, -0.5544])(#FFFFFF), tensor([-0.7126, -1.4422])(#58C4DD), tensor([ 0.4653, -0.5544])(#FFFF00), tensor([1.7884, 2.3283])(#FFFF00), tensor([1.4434, 1.9512])(#FFFF00), tensor([1.7884, 2.3283])(#FFFFFF), tensor([-0.7126, -1.4422])(#FFFF00), tensor([ 0.4653, -0.5544])(#FFFF00), tensor([1.7884, 2.3283])(#58C4DD), tensor([1.4434, 1.9512])(#FFFF00), tensor([1.4434, 1.9512])(#FFFFFF), tensor([-0.7126, -1.4422])(#FFFF00), tensor([ 0.4653, -0.5544])(#58C4DD), tensor([1.7884, 2.3283])(#58C4DD), tensor([1.4434, 1.9512])(#58C4DD)], [tensor([-1.4972, -0.7341])(#FFFFFF), tensor([ 0.3471, -1.7870])(#58C4DD), tensor([ 1.5250, -0.8991])(#58C4DD), tensor([2.8482, 1.9835])(#FFFF00), tensor([2.5031, 1.6065])(#FFFF00), tensor([-0.3193,  0.1537])(#FFFFFF), tensor([ 0.3471, -1.7870])(#58C4DD), tensor([ 1.5250, -0.8991])(#FFFF00), tensor([2.8482, 1.9835])(#FFFF00), tensor([2.5031, 1.6065])(#FFFF00), tensor([1.0038, 3.0363])(#FFFFFF), tensor([ 0.3471, -1.7870])(#FFFF00), tensor([ 1.5250, -0.8991])(#FFFF00), tensor([2.8482, 1.9835])(#58C4DD), tensor([2.5031, 1.6065])(#FFFF00), tensor([0.6587, 2.6593])(#FFFFFF), tensor([ 0.3471, -1.7870])(#FFFF00), tensor([ 1.5250, -0.8991])(#58C4DD), tensor([2.8482, 1.9835])(#58C4DD), tensor([2.5031, 1.6065])(#58C4DD)], [tensor([-0.6535, -4.3134])(#888888), tensor([ 2.2258, -6.9975])(#58C4DD), tensor([ 2.3687, -4.4783])(#58C4DD), tensor([ 3.6919, -1.5957])(#FFFF00), tensor([ 3.3468, -1.9727])(#FFFF00), tensor([ 1.2338, -0.4690])(#888888), tensor([ 3.1111, -5.9089])(#58C4DD), tensor([ 3.3383, -1.9320])(#FFFF00), tensor([4.4013, 1.3608])(#FFFF00), tensor([4.0562, 0.9838])(#FFFF00), tensor([ 1.2698, 13.9438])(#888888), tensor([ 2.8670, -1.4039])(#FFFF00), tensor([ 6.8894, -7.5293])(#FFFF00), tensor([ 3.1282, 12.8687])(#58C4DD), tensor([6.4815, 5.1709])(#FFFF00), tensor([ 0.8461, 12.1914])(#888888), tensor([ 2.6593, -1.3478])(#FFFF00), tensor([ 6.8894, -7.5293])(#58C4DD), tensor([ 3.0355, 11.5156])(#58C4DD), tensor([ 2.7147, 11.1002])(#58C4DD)], [tensor([-7.9849,  4.7945])(#888888), tensor([-7.2286,  4.7477])(#58C4DD), tensor([-2.8831,  2.0460])(#58C4DD), tensor([ 3.6919, -1.5957])(#FFFF00), tensor([ 2.9243, -1.4479])(#FFFF00), tensor([ 1.2338, -0.4690])(#888888), tensor([-3.8875,  2.7854])(#58C4DD), tensor([ 2.9755, -1.4812])(#FFFF00), tensor([4.4013, 1.3608])(#FFFF00), tensor([4.0562, 0.9838])(#FFFF00), tensor([ 1.2698, 13.9438])(#888888), tensor([ 2.8670, -1.4039])(#FFFF00), tensor([0.1939, 0.7885])(#FFFF00), tensor([ 3.1282, 12.8687])(#58C4DD), tensor([6.4815, 5.1709])(#FFFF00), tensor([ 0.8461, 12.1914])(#888888), tensor([ 2.6593, -1.3478])(#FFFF00), tensor([0.1939, 0.7885])(#58C4DD), tensor([ 3.0355, 11.5156])(#58C4DD), tensor([ 2.7147, 11.1002])(#58C4DD)]]\n",
            "0.714157732129097 14.222222222222221 5.315358252525329 8.0 5.713261857032776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.885034153373022 13.712465523613822 8.422848825454711 7.713261857032776 22.253023891448976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6765938607331213 43.11648691813151 15.326490745544433 24.253023891448976 16.409447069168092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unembed:  tensor([[-1.4806,  2.1872],\n",
            "        [ 1.3179, -0.9218]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                              \r"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video src=\"media/jupyter/Video@2025-03-21@11-22-03.mp4\" controls autoplay loop style=\"max-width: 80%;\"  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%manim -qh Video\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "\n",
        "\n",
        "input_dim = 4\n",
        "output_dim = 2\n",
        "train_data, train_labels, test_data, test_labels = get_training_data(input_dim, output_dim, data_seed=999)\n",
        "model = get_seeded_model(999, input_dim, output_dim)\n",
        "train_model(model, train_data, train_labels, test_data, test_labels, num_epochs = 20000, loss_target = 1/(input_dim ** 2 * 4))\n",
        "cache = create_cache(model)\n",
        "arrow_labels = [\"\".join([str(d.item()) for d in v]) for v in train_data]\n",
        "colors = [BLUE, YELLOW, GREEN, RED]\n",
        "arrow_colors = [colors[l] for l in train_labels]\n",
        "vectors = compile_data_vectors(cache, input_labels=arrow_labels, input_colors = arrow_colors)\n",
        "print(\"Labels: \", arrow_labels)\n",
        "\n",
        "class Video(VisualizeTransformer):\n",
        "    def construct(self):\n",
        "        VisualizeTransformer.construct(self)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
